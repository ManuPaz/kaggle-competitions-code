{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3357c80f",
   "metadata": {
    "id": "RSHDBbKmAogM",
    "papermill": {
     "duration": 0.014616,
     "end_time": "2023-12-05T00:20:49.945606",
     "exception": false,
     "start_time": "2023-12-05T00:20:49.930990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NN BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a64eedd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:20:49.975369Z",
     "iopub.status.busy": "2023-12-05T00:20:49.975023Z",
     "iopub.status.idle": "2023-12-05T00:20:50.934006Z",
     "shell.execute_reply": "2023-12-05T00:20:50.932991Z"
    },
    "id": "Yyf-Gw_zAogS",
    "papermill": {
     "duration": 0.976738,
     "end_time": "2023-12-05T00:20:50.936501",
     "exception": false,
     "start_time": "2023-12-05T00:20:49.959763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Copy metrics code from: https://www.kaggle.com/code/metric/event-detection-ap/notebook\n",
    "!cp /kaggle/input/code-zzz/evaluation.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1e0019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:20:50.966800Z",
     "iopub.status.busy": "2023-12-05T00:20:50.966461Z",
     "iopub.status.idle": "2023-12-05T00:21:07.711636Z",
     "shell.execute_reply": "2023-12-05T00:21:07.709976Z"
    },
    "id": "6F1fCkzvAogT",
    "outputId": "1f5ddae6-e632-4a5b-ee9b-dcf296b2e2b8",
    "papermill": {
     "duration": 16.763151,
     "end_time": "2023-12-05T00:21:07.713995",
     "exception": false,
     "start_time": "2023-12-05T00:20:50.950844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "TensorFlow está utilizando una GPU.\n",
      "GPU utilizada: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import logging\n",
    "import polars as pl\n",
    "logger=logging.getLogger()\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "logger.setLevel(logging.INFO)\n",
    "from tqdm import tqdm\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"TensorFlow está utilizando una GPU.\")\n",
    "    print(\"GPU utilizada:\", tf.test.gpu_device_name())\n",
    "else:\n",
    "    print(\"TensorFlow no está utilizando una GPU.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import gc\n",
    "import pickle as pkl\n",
    "from itertools import groupby\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3303a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:07.747572Z",
     "iopub.status.busy": "2023-12-05T00:21:07.746950Z",
     "iopub.status.idle": "2023-12-05T00:21:07.754500Z",
     "shell.execute_reply": "2023-12-05T00:21:07.753537Z"
    },
    "id": "cJ1uqDbdAogT",
    "papermill": {
     "duration": 0.025766,
     "end_time": "2023-12-05T00:21:07.756525",
     "exception": false,
     "start_time": "2023-12-05T00:21:07.730759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from evaluation import score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c14f34",
   "metadata": {
    "id": "WgfZjVjwAogT",
    "papermill": {
     "duration": 0.014833,
     "end_time": "2023-12-05T00:21:07.786811",
     "exception": false,
     "start_time": "2023-12-05T00:21:07.771978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MODEL TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b08290",
   "metadata": {
    "id": "Wqjzmlt7AogT",
    "papermill": {
     "duration": 0.014365,
     "end_time": "2023-12-05T00:21:07.816216",
     "exception": false,
     "start_time": "2023-12-05T00:21:07.801851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is used as the target whether the subject is sleeping or not (1 if they are and 0 if not). There are series with events that have 'step=null'. In these series, there are chunks of data where it is unknown where the previous or next event is. These data points are labeled as 'nan', and will be used only as features since the loss function uses a mask to compute the loss only on data points that do not have a 'nan' target.\n",
    "\n",
    "Based on this target \"sleep\", events are constructed for evaluation and final submission using the 'get_event' function, which is being used in other notebooks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101ef52a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:07.845962Z",
     "iopub.status.busy": "2023-12-05T00:21:07.845688Z",
     "iopub.status.idle": "2023-12-05T00:21:07.849826Z",
     "shell.execute_reply": "2023-12-05T00:21:07.848896Z"
    },
    "id": "Skz0vh5_AogT",
    "papermill": {
     "duration": 0.021435,
     "end_time": "2023-12-05T00:21:07.851806",
     "exception": false,
     "start_time": "2023-12-05T00:21:07.830371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET=\"sleep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "846a66c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:07.881758Z",
     "iopub.status.busy": "2023-12-05T00:21:07.881465Z",
     "iopub.status.idle": "2023-12-05T00:21:07.885314Z",
     "shell.execute_reply": "2023-12-05T00:21:07.884524Z"
    },
    "papermill": {
     "duration": 0.021199,
     "end_time": "2023-12-05T00:21:07.887244",
     "exception": false,
     "start_time": "2023-12-05T00:21:07.866045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH= \"/kaggle/input/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727e8e68",
   "metadata": {
    "id": "11W438iZAogU",
    "papermill": {
     "duration": 0.014528,
     "end_time": "2023-12-05T00:21:07.916301",
     "exception": false,
     "start_time": "2023-12-05T00:21:07.901773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af03b594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:07.946844Z",
     "iopub.status.busy": "2023-12-05T00:21:07.946156Z",
     "iopub.status.idle": "2023-12-05T00:21:07.950569Z",
     "shell.execute_reply": "2023-12-05T00:21:07.949506Z"
    },
    "id": "yC1spq9oAogU",
    "papermill": {
     "duration": 0.02212,
     "end_time": "2023-12-05T00:21:07.952861",
     "exception": false,
     "start_time": "2023-12-05T00:21:07.930741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "STEPS_PER_EPOCH = 300\n",
    "NUM_EPOCHS=15\n",
    "WARMUP_STEPS = 64\n",
    "GPU_BATCH_SIZE=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85552ad9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:07.987168Z",
     "iopub.status.busy": "2023-12-05T00:21:07.986562Z",
     "iopub.status.idle": "2023-12-05T00:21:07.991007Z",
     "shell.execute_reply": "2023-12-05T00:21:07.990134Z"
    },
    "id": "H5wwd1ZWAogU",
    "papermill": {
     "duration": 0.023163,
     "end_time": "2023-12-05T00:21:07.993044",
     "exception": false,
     "start_time": "2023-12-05T00:21:07.969881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPTMIZER_BETA1=0.9\n",
    "OPTMIZER_BETA2=0.98\n",
    "OPTMIZER_EPSILON=1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b4e88f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:08.071670Z",
     "iopub.status.busy": "2023-12-05T00:21:08.070929Z",
     "iopub.status.idle": "2023-12-05T00:21:08.075643Z",
     "shell.execute_reply": "2023-12-05T00:21:08.074614Z"
    },
    "id": "pnDj1t0AAogU",
    "papermill": {
     "duration": 0.069208,
     "end_time": "2023-12-05T00:21:08.077735",
     "exception": false,
     "start_time": "2023-12-05T00:21:08.008527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VALIDATE =False\n",
    "## 5 folds in the fold_ids.pkl file (random folds of the 277 train series_ids, this way each full series is only in one fold). In this version only fold1 is used for training the model.\n",
    "\n",
    "SAMPLE_NORMALIZE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f89222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:08.110056Z",
     "iopub.status.busy": "2023-12-05T00:21:08.109772Z",
     "iopub.status.idle": "2023-12-05T00:21:08.121501Z",
     "shell.execute_reply": "2023-12-05T00:21:08.120654Z"
    },
    "papermill": {
     "duration": 0.030223,
     "end_time": "2023-12-05T00:21:08.123524",
     "exception": false,
     "start_time": "2023-12-05T00:21:08.093301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelSpec:\n",
    "    def __init__(self,model_name, padding, use_temp,  model_type,drop_initial_date, sample_normalize,initial_hour=12, patch_size=12,model_dim=320,lstm_layers=5,use_tam_consider=False,TAM_RESHAPE=1,weight=1,STRIDE=0):\n",
    "        self.model_name=model_name\n",
    "        self.padding=padding\n",
    "        self.use_temp=use_temp\n",
    "        self.model_type=model_type\n",
    "        self.drop_initial_date=drop_initial_date\n",
    "        self.sample_normalize=sample_normalize\n",
    "        self.initial_hour=initial_hour\n",
    "        self.use_tam_consider=use_tam_consider\n",
    "        self.TAM_RESHAPE=TAM_RESHAPE\n",
    "        if self.model_type==LINEAR:\n",
    "            self.CFG=CFG .copy()\n",
    "        elif self.model_type==LINEAR_lstm_dropout:\n",
    "            self.CFG=CFG_lstm_dropout.copy()\n",
    "        elif self.model_type==CNN:\n",
    "            self.CFG = CFG_CNN .copy()\n",
    "        elif self.model_type==ATT:\n",
    "            self.CFG=CFG_Att.copy()\n",
    "            \n",
    "        elif self.model_type==CONV1:\n",
    "            self.CFG=CFGConv1.copy()\n",
    "        elif self.model_type==CONV_5:\n",
    "            self.CFG=CFGConv1.copy()\n",
    "        elif self.model_type==CONV_6:\n",
    "            self.CFG=CFGConv1.copy()\n",
    "        elif self.model_type==GRU:\n",
    "            self.CFG = CFG .copy()\n",
    "        elif self.model_type==CONV1_LSTMDROPOUT:\n",
    "              self.CFG=CFGConv1.copy()\n",
    "        self.CFG[  \"patch_size\"] = patch_size\n",
    "        \n",
    "        self.CFG[  'model_dim']=model_dim\n",
    "        self.CFG[   'model_num_lstm_layers'] =  lstm_layers\n",
    "        if self.model_type!=ATT:\n",
    "            self.CFG['feature_mixing_dim']=model_dim\n",
    "        self.patch_size= patch_size\n",
    "        if self.use_temp:\n",
    "            self.dim = self.CFG[\"patch_size\"]*2 +2 # 2 numeric features * patch size + 2 more features (sine and cosine of day time)\n",
    "        else:\n",
    "            self.dim =self.CFG[\"patch_size\"]*2\n",
    "            \n",
    "        self.weight=weight\n",
    "      \n",
    "        self.STRIDE=STRIDE\n",
    "        if   self.STRIDE!=0:\n",
    "            self.CFG[\"stride\"]=self.STRIDE\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de8ea023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:08.154010Z",
     "iopub.status.busy": "2023-12-05T00:21:08.153724Z",
     "iopub.status.idle": "2023-12-05T00:21:08.158703Z",
     "shell.execute_reply": "2023-12-05T00:21:08.157835Z"
    },
    "papermill": {
     "duration": 0.022509,
     "end_time": "2023-12-05T00:21:08.160639",
     "exception": false,
     "start_time": "2023-12-05T00:21:08.138130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "REPLACE=\"replace\"\n",
    "EXTEND=\"extend\"\n",
    "LINEAR=\"linear\"\n",
    "ATT=\"att\"\n",
    "CNN=\"cnn\"\n",
    "CONV1=\"conv1\"\n",
    "CONV_5=\"CONV_5\"\n",
    "CONV_6=\"CONV_6\"\n",
    "CONV1_LSTMDROPOUT=\"CONV1_LSTMDROPOUT\"\n",
    "CONV2=\"conv2\"\n",
    "GRU=\"GRU\"\n",
    "LINEAR_lstm_dropout=\"LINEAR_lstm_dropout\"\n",
    "DEFAULT_PATCH_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20ce794a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:08.192608Z",
     "iopub.status.busy": "2023-12-05T00:21:08.192304Z",
     "iopub.status.idle": "2023-12-05T00:21:08.207392Z",
     "shell.execute_reply": "2023-12-05T00:21:08.206526Z"
    },
    "papermill": {
     "duration": 0.033803,
     "end_time": "2023-12-05T00:21:08.209475",
     "exception": false,
     "start_time": "2023-12-05T00:21:08.175672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG= {\n",
    "   \"num_epochs\":NUM_EPOCHS,\n",
    "   \"steps_per_epoch\":STEPS_PER_EPOCH,\n",
    "   \"patch_size\":DEFAULT_PATCH_SIZE,\n",
    "   \"block_size\":17280,\n",
    "   \"stride\": 17280,\n",
    "   'model_dim': 320,\n",
    "   'time_mixing_dim':1440,\n",
    "   'feature_mixing_dim':320,\n",
    "   'model_num_heads': 6,\n",
    "   'model_num_encoder_layers': 5,\n",
    "   'model_num_lstm_layers': 5,\n",
    "   'model_first_dropout': 0.5,\n",
    "   'model_second_dropout':0.5,\n",
    "   'model_encoder_dropout': 0.1,\n",
    "   'model_mha_dropout': 0.0,\n",
    "}\n",
    "\n",
    "CFG_lstm_dropout = {\n",
    "   \"num_epochs\":NUM_EPOCHS,\n",
    "   \"steps_per_epoch\":STEPS_PER_EPOCH,\n",
    "   \"patch_size\":10,\n",
    "   \"block_size\":17280,\n",
    "   \"stride\": 17280,\n",
    "   'model_dim': 160,\n",
    "   'time_mixing_dim':1440,\n",
    "   'feature_mixing_dim':160,\n",
    "   'model_num_heads': 6,\n",
    "   'model_num_encoder_layers': 5,\n",
    "   'model_num_lstm_layers': 5,\n",
    "   'model_first_dropout': 0.5,\n",
    "   'model_second_dropout':0.5,\n",
    "   'model_encoder_dropout': 0.1,\n",
    "   'model_mha_dropout': 0.0,\n",
    "}\n",
    "CFG_Att  = {\n",
    "   \"num_epochs\":NUM_EPOCHS,\n",
    "   \"steps_per_epoch\":STEPS_PER_EPOCH,\n",
    "   \"patch_size\":10,\n",
    "   \"block_size\":17280,\n",
    "   \"stride\": 17280,\n",
    "   'model_dim': 160,\n",
    "   'time_mixing_dim':1440,\n",
    "   'feature_mixing_dim':80,\n",
    "   'model_num_heads': 6,\n",
    "   'model_num_encoder_layers': 5,\n",
    "   'model_num_lstm_layers': 2,\n",
    "   'model_first_dropout': 0.5,\n",
    "   'model_second_dropout':0.5,\n",
    "   'model_encoder_dropout': 0.1,\n",
    "   'model_mha_dropout': 0.0,\n",
    "   'model_transformer_layers':3,\n",
    "   \"transformer_dim\":320\n",
    "}\n",
    "\n",
    "CFG_CNN = {\n",
    "   \"num_epochs\":NUM_EPOCHS,\n",
    "   \"steps_per_epoch\":STEPS_PER_EPOCH,\n",
    "   \"patch_size\":10,\n",
    "   \"block_size\":17280,\n",
    "   \"stride\": 17280,\n",
    "   'model_dim': 160,\n",
    "   'time_mixing_dim':1440,\n",
    "   'feature_mixing_dim':160,\n",
    "   'model_num_heads': 6,\n",
    "   'model_num_encoder_layers': 5,\n",
    "   'model_num_lstm_layers': 2,\n",
    "   'model_cnn_layers':3,\n",
    "   'model_first_dropout': 0.5,\n",
    "   'model_second_dropout':0.5,\n",
    "   'model_encoder_dropout': 0.1,\n",
    "   'model_mha_dropout': 0.0,\n",
    "}\n",
    "\n",
    "CFGConv1 = {\n",
    "   \"num_epochs\":NUM_EPOCHS,\n",
    "   \"steps_per_epoch\":STEPS_PER_EPOCH,\n",
    "   \"patch_size\":1,\n",
    "   \"block_size\":17280,\n",
    "   \"stride\": 17280,\n",
    "   'model_dim': 160,\n",
    "   'time_mixing_dim':1440,\n",
    "   'feature_mixing_dim':160,\n",
    "   'model_num_heads': 6,\n",
    "   'model_num_encoder_layers': 3,\n",
    "   'model_num_lstm_layers': 5,\n",
    "   'model_first_dropout': 0.2,\n",
    "   'model_second_dropout':0.5,\n",
    "   'model_encoder_dropout': 0.1,\n",
    "   'model_mha_dropout': 0.0,\n",
    "}\n",
    "CFG_CONV1_LSTMDROPOUT  = {\n",
    "   \"num_epochs\":NUM_EPOCHS,\n",
    "   \"steps_per_epoch\":STEPS_PER_EPOCH,\n",
    "   \"patch_size\":1,\n",
    "   \"block_size\":17280,\n",
    "   \"stride\": 17280,\n",
    "   'model_dim': 160,\n",
    "   'time_mixing_dim':1440,\n",
    "   'feature_mixing_dim':160,\n",
    "   'model_num_heads': 6,\n",
    "   'model_num_encoder_layers': 3,\n",
    "   'model_num_lstm_layers': 5,\n",
    "   'model_first_dropout': 0.2,\n",
    "   'model_second_dropout':0.5,\n",
    "   'model_encoder_dropout': 0.1,\n",
    "   'model_mha_dropout': 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aef32ce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:08.240636Z",
     "iopub.status.busy": "2023-12-05T00:21:08.240369Z",
     "iopub.status.idle": "2023-12-05T00:21:08.244396Z",
     "shell.execute_reply": "2023-12-05T00:21:08.243502Z"
    },
    "papermill": {
     "duration": 0.021911,
     "end_time": "2023-12-05T00:21:08.246407",
     "exception": false,
     "start_time": "2023-12-05T00:21:08.224496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if VALIDATE:\n",
    "    file = \"/kaggle/input/zzz-data-train/data_train.parquet\"\n",
    "else:\n",
    "    file=\"/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8852ff01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:08.277755Z",
     "iopub.status.busy": "2023-12-05T00:21:08.277493Z",
     "iopub.status.idle": "2023-12-05T00:21:08.296808Z",
     "shell.execute_reply": "2023-12-05T00:21:08.296126Z"
    },
    "papermill": {
     "duration": 0.03716,
     "end_time": "2023-12-05T00:21:08.298804",
     "exception": false,
     "start_time": "2023-12-05T00:21:08.261644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_ids=pkl.load(open(\"/kaggle/input/zzz-data-train/dict_ids.pkl\",\"rb\"))\n",
    "swapped_dict={value:key for key,value in dict_ids.items()}\n",
    "fold_ids=pkl.load(open(\"/kaggle/input/zzz-data-train/fold_ids.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f8b516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:08.330482Z",
     "iopub.status.busy": "2023-12-05T00:21:08.330222Z",
     "iopub.status.idle": "2023-12-05T00:21:08.546117Z",
     "shell.execute_reply": "2023-12-05T00:21:08.545216Z"
    },
    "papermill": {
     "duration": 0.23401,
     "end_time": "2023-12-05T00:21:08.548118",
     "exception": false,
     "start_time": "2023-12-05T00:21:08.314108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['038441c925bb', '03d92c9f6f8a', '0402a003dae9'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_test  = pd.read_parquet(file, columns=['series_id'])\n",
    "ids_test = ids_test.series_id.unique()\n",
    "ids_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e67de2b",
   "metadata": {
    "papermill": {
     "duration": 0.014739,
     "end_time": "2023-12-05T00:21:08.577513",
     "exception": false,
     "start_time": "2023-12-05T00:21:08.562774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f66e9389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:08.608638Z",
     "iopub.status.busy": "2023-12-05T00:21:08.607958Z",
     "iopub.status.idle": "2023-12-05T00:21:09.628128Z",
     "shell.execute_reply": "2023-12-05T00:21:09.627036Z"
    },
    "papermill": {
     "duration": 1.037824,
     "end_time": "2023-12-05T00:21:09.630241",
     "exception": false,
     "start_time": "2023-12-05T00:21:08.592417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 52.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "if not VALIDATE:\n",
    "   \n",
    "    # Abre el archivo parquet\n",
    "    pf = pq.ParquetFile(file)\n",
    "    !mkdir series\n",
    "    # Cantidad de grupos de filas en el archivo parquet\n",
    "    num_row_groups = pf.num_row_groups\n",
    "\n",
    "    # Procesar grupo por grupo\n",
    "    for r in tqdm(range(num_row_groups)):\n",
    "        # Leer un grupo de filas\n",
    "        table = pf.read_row_group(r, columns=[\"anglez\", \"enmo\", \"series_id\",\"step\",\"sleep\",\"timestamp\",])\n",
    "        df = table.to_pandas()\n",
    "\n",
    "        # Procesa y guarda cada series_id en su archivo\n",
    "        for id_, subset in df.groupby(\"series_id\"):\n",
    "            # Determina la ruta del archivo\n",
    "            file_path = f\"series/series_{id_}.parquet\"\n",
    "\n",
    "            if os.path.exists(file_path):\n",
    "                # Si el archivo ya existe, lee el contenido existente y concatena\n",
    "                existing_df = pd.read_parquet(file_path)\n",
    "                combined_df = pd.concat([existing_df, subset], axis=0)\n",
    "                combined_df.to_parquet(file_path, index=False)\n",
    "            else:\n",
    "                # Si no, solo guarda el subconjunto\n",
    "                subset.to_parquet(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04d4f216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:09.663385Z",
     "iopub.status.busy": "2023-12-05T00:21:09.663024Z",
     "iopub.status.idle": "2023-12-05T00:21:09.667758Z",
     "shell.execute_reply": "2023-12-05T00:21:09.666847Z"
    },
    "id": "JsOYBqUSAogV",
    "papermill": {
     "duration": 0.024776,
     "end_time": "2023-12-05T00:21:09.670053",
     "exception": false,
     "start_time": "2023-12-05T00:21:09.645277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_features= [\"anglez\", \"enmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fdf7180",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:09.703999Z",
     "iopub.status.busy": "2023-12-05T00:21:09.703742Z",
     "iopub.status.idle": "2023-12-05T00:21:09.716759Z",
     "shell.execute_reply": "2023-12-05T00:21:09.715926Z"
    },
    "papermill": {
     "duration": 0.032779,
     "end_time": "2023-12-05T00:21:09.718648",
     "exception": false,
     "start_time": "2023-12-05T00:21:09.685869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class EncoderConv1(tf.keras.Model):\n",
    "    def __init__(self,j):\n",
    "        super().__init__()\n",
    "\n",
    "        self.first_linear = tf.keras.layers.Dense(CFGConv1['time_mixing_dim'])\n",
    "        self.second_linear = tf.keras.layers.Dense(CFGConv1['feature_mixing_dim'])\n",
    "\n",
    "\n",
    "        self.conv1=tf.keras.layers.Conv1D(32*(2**j),3,strides=1,padding=\"same\",)\n",
    "        self.conv2=tf.keras.layers.Conv1D(32*(2**j),3,strides=1,padding=\"same\",)\n",
    "        self.conv3=tf.keras.layers.Conv1D(32*(2**j),3,strides=1,padding=\"same\",)\n",
    "        #self.norm=tf.keras.layers.BatchNormalization()\n",
    "        self.max_pool=tf.keras.layers.AveragePooling1D( pool_size=2)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "\n",
    "\n",
    "\n",
    "        res=x\n",
    "\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.conv3(x)\n",
    "        #x=self.norm(x)\n",
    "        x=tf.keras.layers.ReLU(  )(x)\n",
    "        #x = self.dropout( x)\n",
    "        x= self.max_pool(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ModelConv1(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoders = [EncoderConv1(i+1) for i in range( CFGConv1['model_num_encoder_layers'])]\n",
    "        self.lstm_layers = [tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(CFGConv1['model_dim'], return_sequences=True)) for _ in range(CFGConv1['model_num_lstm_layers'])]\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(64)\n",
    "\n",
    "        #self.first_dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.last_linear = tf.keras.layers.Dense(2)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(CFGConv1['model_num_encoder_layers']): x = self.encoders[i](x)\n",
    "\n",
    "        for i in range(CFGConv1['model_num_lstm_layers']):x= self.lstm_layers[i](x)\n",
    "        x =self.linear(x)\n",
    "        x = self.last_linear(x)\n",
    "        x = tf.nn.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea6bc5d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:09.749485Z",
     "iopub.status.busy": "2023-12-05T00:21:09.749226Z",
     "iopub.status.idle": "2023-12-05T00:21:09.772217Z",
     "shell.execute_reply": "2023-12-05T00:21:09.771422Z"
    },
    "papermill": {
     "duration": 0.040414,
     "end_time": "2023-12-05T00:21:09.774083",
     "exception": false,
     "start_time": "2023-12-05T00:21:09.733669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderConv6(tf.keras.Model):\n",
    "    def __init__(self,j):\n",
    "        super().__init__()\n",
    "        self.j=j\n",
    "        self.first_linear = tf.keras.layers.Dense(CFGConv1['time_mixing_dim'])\n",
    "        self.second_linear = tf.keras.layers.Dense(CFGConv1['feature_mixing_dim'])\n",
    "\n",
    "\n",
    "        self.conv1=tf.keras.layers.Conv1D(32*(2**j),3,strides=1,padding=\"same\",)\n",
    "        self.conv2=tf.keras.layers.Conv1D(32*(2**j),3,strides=1,padding=\"same\",)\n",
    "        self.conv3=tf.keras.layers.Conv1D(32*(2**j),3,strides=1,padding=\"same\",)\n",
    "        #self.norm=tf.keras.layers.BatchNormalization()\n",
    "        if self.j==1:\n",
    "          POOL=2\n",
    "        else:\n",
    "          POOL=3\n",
    "        self.max_pool=tf.keras.layers.AveragePooling1D( pool_size= POOL)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "\n",
    "\n",
    "\n",
    "        res=x\n",
    "\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.conv3(x)\n",
    "        #x=self.norm(x)\n",
    "        x=tf.keras.layers.ReLU(  )(x)\n",
    "        #x = self.dropout( x)\n",
    "        if self.j<3:\n",
    "          x= self.max_pool(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class ModelConv6(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoders = [EncoderConv6(i+1) for i in range( CFGConv1['model_num_encoder_layers'])]\n",
    "        self.lstm_layers = [tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(CFGConv1['model_dim'], return_sequences=True)) for _ in range(CFGConv1['model_num_lstm_layers'])]\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(64)\n",
    "\n",
    "        #self.first_dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.last_linear = tf.keras.layers.Dense(2)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(CFGConv1['model_num_encoder_layers']): x = self.encoders[i](x)\n",
    "\n",
    "        for i in range(CFGConv1['model_num_lstm_layers']):x= self.lstm_layers[i](x)\n",
    "        x =self.linear(x)\n",
    "        x = self.last_linear(x)\n",
    "        x = tf.nn.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    \n",
    "class EncoderConv5(tf.keras.Model):\n",
    "    def __init__(self,j):\n",
    "        super().__init__()\n",
    "        self.j=j\n",
    "        self.first_linear = tf.keras.layers.Dense(CFGConv1['time_mixing_dim'])\n",
    "        self.second_linear = tf.keras.layers.Dense(CFGConv1['feature_mixing_dim'])\n",
    "\n",
    "\n",
    "        self.conv1=tf.keras.layers.Conv1D(32*(2**j),3,strides=1,padding=\"same\",)\n",
    "        self.conv2=tf.keras.layers.Conv1D(32*(2**j),3,strides=1,padding=\"same\",)\n",
    "        self.conv3=tf.keras.layers.Conv1D(32*(2**j),3,strides=1,padding=\"same\",)\n",
    "        #self.norm=tf.keras.layers.BatchNormalization()\n",
    "        self.max_pool=tf.keras.layers.AveragePooling1D( pool_size=2)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "\n",
    "\n",
    "\n",
    "        res=x\n",
    "\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.conv3(x)\n",
    "        #x=self.norm(x)\n",
    "        x=tf.keras.layers.ReLU(  )(x)\n",
    "        #x = self.dropout( x)\n",
    "        if self.j<3:\n",
    "          x= self.max_pool(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class ModelConv5(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoders = [EncoderConv5(i+1) for i in range( CFGConv1['model_num_encoder_layers'])]\n",
    "        self.lstm_layers = [tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(CFGConv1['model_dim'], return_sequences=True)) for _ in range(CFGConv1['model_num_lstm_layers'])]\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(64)\n",
    "\n",
    "        #self.first_dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.last_linear = tf.keras.layers.Dense(2)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(CFGConv1['model_num_encoder_layers']): x = self.encoders[i](x)\n",
    "\n",
    "        for i in range(CFGConv1['model_num_lstm_layers']):x= self.lstm_layers[i](x)\n",
    "        x =self.linear(x)\n",
    "        x = self.last_linear(x)\n",
    "        x = tf.nn.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b939bb3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:09.806531Z",
     "iopub.status.busy": "2023-12-05T00:21:09.806216Z",
     "iopub.status.idle": "2023-12-05T00:21:09.819998Z",
     "shell.execute_reply": "2023-12-05T00:21:09.819076Z"
    },
    "papermill": {
     "duration": 0.033305,
     "end_time": "2023-12-05T00:21:09.822079",
     "exception": false,
     "start_time": "2023-12-05T00:21:09.788774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class  EncoderConv1_LSTMDROPOUT(tf.keras.Model):\n",
    "    def __init__(self,j):\n",
    "        super().__init__()\n",
    "\n",
    "        self.first_linear = tf.keras.layers.Dense(CFG_CONV1_LSTMDROPOUT['time_mixing_dim'])\n",
    "        self.second_linear = tf.keras.layers.Dense(CFG_CONV1_LSTMDROPOUT['feature_mixing_dim'])\n",
    "\n",
    "\n",
    "        self.conv1=tf.keras.layers.Conv1D(32*(2**j),3,strides=1,padding=\"same\",)\n",
    "        self.conv2=tf.keras.layers.Conv1D(32*(2**j),3,strides=1,padding=\"same\",)\n",
    "        self.conv3=tf.keras.layers.Conv1D(32*(2**j),3,strides=1,padding=\"same\",)\n",
    "        #self.norm=tf.keras.layers.BatchNormalization()\n",
    "        self.max_pool=tf.keras.layers.AveragePooling1D( pool_size=2)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "\n",
    "\n",
    "\n",
    "        res=x\n",
    "\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.conv3(x)\n",
    "        #x=self.norm(x)\n",
    "        x=tf.keras.layers.ReLU(  )(x)\n",
    "        #x = self.dropout( x)\n",
    "        x= self.max_pool(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class ModelConv1_LSTMDROPOUT(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoders = [EncoderConv1_LSTMDROPOUT(i+1) for i in range( CFG_CONV1_LSTMDROPOUT['model_num_encoder_layers'])]\n",
    "        self.lstm_layers = [tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(CFG_CONV1_LSTMDROPOUT['model_dim'], return_sequences=True,dropout=0.2)) for _ in range(CFG_CONV1_LSTMDROPOUT['model_num_lstm_layers'])]\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(64)\n",
    "\n",
    "        #self.first_dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.last_linear = tf.keras.layers.Dense(2)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(CFG_CONV1_LSTMDROPOUT['model_num_encoder_layers']): x = self.encoders[i](x)\n",
    "\n",
    "        for i in range(CFG_CONV1_LSTMDROPOUT['model_num_lstm_layers']):x= self.lstm_layers[i](x)\n",
    "        x =self.linear(x)\n",
    "        x = self.last_linear(x)\n",
    "        x = tf.nn.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fc96625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:09.855359Z",
     "iopub.status.busy": "2023-12-05T00:21:09.855061Z",
     "iopub.status.idle": "2023-12-05T00:21:09.868321Z",
     "shell.execute_reply": "2023-12-05T00:21:09.867452Z"
    },
    "papermill": {
     "duration": 0.032112,
     "end_time": "2023-12-05T00:21:09.870368",
     "exception": false,
     "start_time": "2023-12-05T00:21:09.838256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,CFG):\n",
    "        super().__init__()\n",
    "\n",
    "        self.first_linear = tf.keras.layers.Dense(CFG['time_mixing_dim'])\n",
    "        self.second_linear = tf.keras.layers.Dense(CFG['feature_mixing_dim'])\n",
    "\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "        self.first_dropout = tf.keras.layers.Dropout(CFG['model_first_dropout'])\n",
    "\n",
    "        self.second_dropout = tf.keras.layers.Dropout(CFG['model_second_dropout'])\n",
    "      \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        \n",
    "        \n",
    "        # time mixing\n",
    "        \"\"\"time_mixing= tf.transpose(x,perm=[0,2,1])\n",
    "        time_mixing  = self.first_linear(time_mixing )\n",
    "\n",
    "        time_mixing =tf.keras.layers.ReLU( )(time_mixing)\n",
    "\n",
    "        time_mixing  = self.first_dropout(time_mixing )\n",
    "\n",
    "        time_mixing =tf.transpose(  time_mixing,perm=[0,2,1])\n",
    "\n",
    "        x=self.add ([x,time_mixing])\"\"\"\n",
    "\n",
    "        features_mixing = self.second_linear(x )\n",
    "\n",
    "        features_mixing  = tf.keras.layers.ReLU(  )(features_mixing)\n",
    "\n",
    "        features_mixing   = self.second_dropout( features_mixing )\n",
    "\n",
    "        x=self.add ([x,features_mixing ])\n",
    "        return x\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self,CFG):\n",
    "        super().__init__()\n",
    "        self.CFG=CFG\n",
    "        self.encoders = [Encoder( self.CFG) for i in range( self.CFG['model_num_encoder_layers'])]\n",
    "\n",
    "        self.lstm_layers = [tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.CFG['model_dim'], return_sequences=True)) for _ in range(self.CFG['model_num_lstm_layers'])]\n",
    "\n",
    "        self.first_linear = tf.keras.layers.Dense(self.CFG['feature_mixing_dim'])\n",
    "        self.first_dropout = tf.keras.layers.Dropout(0.1)\n",
    "        self.last_linear = tf.keras.layers.Dense(2)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "\n",
    "        x=self.first_linear(x)\n",
    "        x=self.first_dropout(x)\n",
    "        for i in range(self.CFG['model_num_encoder_layers']): x = self.encoders[i](x)\n",
    "\n",
    "        for i in range(self.CFG['model_num_lstm_layers']):x= self.lstm_layers[i](x)\n",
    "        x = self.last_linear(x)\n",
    "        x = tf.nn.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f50ab083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:09.903208Z",
     "iopub.status.busy": "2023-12-05T00:21:09.902892Z",
     "iopub.status.idle": "2023-12-05T00:21:09.915264Z",
     "shell.execute_reply": "2023-12-05T00:21:09.914315Z"
    },
    "papermill": {
     "duration": 0.031439,
     "end_time": "2023-12-05T00:21:09.917341",
     "exception": false,
     "start_time": "2023-12-05T00:21:09.885902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderGRU(tf.keras.Model):\n",
    "    def __init__(self,CFG):\n",
    "        super().__init__()\n",
    "\n",
    "        self.first_linear = tf.keras.layers.Dense(CFG['time_mixing_dim'])\n",
    "        self.second_linear = tf.keras.layers.Dense(CFG['feature_mixing_dim'])\n",
    "\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "        self.first_dropout = tf.keras.layers.Dropout(CFG['model_first_dropout'])\n",
    "\n",
    "        self.second_dropout = tf.keras.layers.Dropout(CFG['model_second_dropout'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        features_mixing = self.second_linear(x )\n",
    "\n",
    "        features_mixing  = tf.keras.layers.ReLU(  )(features_mixing)\n",
    "\n",
    "        features_mixing   = self.second_dropout( features_mixing )\n",
    "\n",
    "        x=self.add ([x,features_mixing ])\n",
    "        return x\n",
    "\n",
    "class ModelGRU(tf.keras.Model):\n",
    "    def __init__(self,CFG):\n",
    "        super().__init__()\n",
    "        self.CFG=CFG\n",
    "        self.encoders = [EncoderGRU(CFG) for i in range( CFG['model_num_encoder_layers'])]\n",
    "\n",
    "        self.lstm_layers = [tf.keras.layers.Bidirectional(tf.keras.layers.GRU(CFG['model_dim'], return_sequences=True)) for _ in range(CFG['model_num_lstm_layers'])]\n",
    "\n",
    "        self.first_linear = tf.keras.layers.Dense(CFG['feature_mixing_dim'])\n",
    "        self.first_dropout = tf.keras.layers.Dropout(0.1)\n",
    "        self.last_linear = tf.keras.layers.Dense(2)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "\n",
    "        x=self.first_linear(x)\n",
    "        x=self.first_dropout(x)\n",
    "        for i in range(self.CFG['model_num_encoder_layers']): x = self.encoders[i](x)\n",
    "\n",
    "        for i in range(self.CFG['model_num_lstm_layers']):x= self.lstm_layers[i](x)\n",
    "        x = self.last_linear(x)\n",
    "        x = tf.nn.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8222e14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:09.949635Z",
     "iopub.status.busy": "2023-12-05T00:21:09.949379Z",
     "iopub.status.idle": "2023-12-05T00:21:09.960731Z",
     "shell.execute_reply": "2023-12-05T00:21:09.959941Z"
    },
    "papermill": {
     "duration": 0.029446,
     "end_time": "2023-12-05T00:21:09.962640",
     "exception": false,
     "start_time": "2023-12-05T00:21:09.933194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Encoder_lstm_dropout(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.first_linear = tf.keras.layers.Dense(CFG_lstm_dropout['time_mixing_dim'])\n",
    "        self.second_linear = tf.keras.layers.Dense(CFG_lstm_dropout['feature_mixing_dim'])\n",
    "\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "        self.first_dropout = tf.keras.layers.Dropout(CFG_lstm_dropout['model_first_dropout'])\n",
    "\n",
    "        self.second_dropout = tf.keras.layers.Dropout(CFG_lstm_dropout['model_second_dropout'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        features_mixing = self.second_linear(x )\n",
    "\n",
    "        features_mixing  = tf.keras.layers.ReLU(  )(features_mixing)\n",
    "\n",
    "        features_mixing   = self.second_dropout( features_mixing )\n",
    "\n",
    "        x=self.add ([x,features_mixing ])\n",
    "        return x\n",
    "\n",
    "class Model_lstm_dropout(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoders = [Encoder_lstm_dropout() for i in range( CFG_lstm_dropout['model_num_encoder_layers'])]\n",
    "\n",
    "        self.lstm_layers = [tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(CFG_lstm_dropout['model_dim'], return_sequences=True,dropout=0.2)) for _ in range(CFG_lstm_dropout['model_num_lstm_layers'])]\n",
    "\n",
    "        self.first_linear = tf.keras.layers.Dense(CFG_lstm_dropout['feature_mixing_dim'])\n",
    "        self.first_dropout = tf.keras.layers.Dropout(0.1)\n",
    "        self.last_linear = tf.keras.layers.Dense(2)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "\n",
    "        x=self.first_linear(x)\n",
    "        x=self.first_dropout(x)\n",
    "        for i in range(CFG_lstm_dropout['model_num_encoder_layers']): x = self.encoders[i](x)\n",
    "\n",
    "        for i in range(CFG_lstm_dropout['model_num_lstm_layers']):x= self.lstm_layers[i](x)\n",
    "        x = self.last_linear(x)\n",
    "        x = tf.nn.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970adc5c",
   "metadata": {
    "id": "ZU6n5hD0AogV",
    "papermill": {
     "duration": 0.014438,
     "end_time": "2023-12-05T00:21:09.991782",
     "exception": false,
     "start_time": "2023-12-05T00:21:09.977344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  GET AND BUILD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a27651",
   "metadata": {
    "id": "StaNPDdrAogV",
    "papermill": {
     "duration": 0.015143,
     "end_time": "2023-12-05T00:21:10.021979",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.006836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The training data is constructed in another notebook exactly the same way as is test data here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8e6c72a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.053482Z",
     "iopub.status.busy": "2023-12-05T00:21:10.052683Z",
     "iopub.status.idle": "2023-12-05T00:21:10.106789Z",
     "shell.execute_reply": "2023-12-05T00:21:10.105901Z"
    },
    "papermill": {
     "duration": 0.071843,
     "end_time": "2023-12-05T00:21:10.109003",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.037160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "events=pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\").dropna(subset=\"timestamp\")\n",
    "events_check=pd.read_csv(f\"{PATH}/child-mind-institute-detect-sleep-states/train_events.csv\").dropna(subset=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e34c71d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.140693Z",
     "iopub.status.busy": "2023-12-05T00:21:10.139957Z",
     "iopub.status.idle": "2023-12-05T00:21:10.145230Z",
     "shell.execute_reply": "2023-12-05T00:21:10.144346Z"
    },
    "id": "KQn0-ih7AogW",
    "papermill": {
     "duration": 0.023305,
     "end_time": "2023-12-05T00:21:10.147211",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.123906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_normalize(sample):\n",
    "    mean = tf.math.reduce_mean(sample,axis=0)\n",
    "    std = tf.math.reduce_std(sample,axis=0)\n",
    "    sample = tf.math.divide_no_nan(sample-mean, std)\n",
    "\n",
    "    return sample.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d1f94",
   "metadata": {
    "papermill": {
     "duration": 0.014731,
     "end_time": "2023-12-05T00:21:10.177611",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.162880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0a8d419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.210642Z",
     "iopub.status.busy": "2023-12-05T00:21:10.210360Z",
     "iopub.status.idle": "2023-12-05T00:21:10.216272Z",
     "shell.execute_reply": "2023-12-05T00:21:10.215404Z"
    },
    "papermill": {
     "duration": 0.024879,
     "end_time": "2023-12-05T00:21:10.218298",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.193419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def truncate_days(df_,id_):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        swaped_dict={value:key for key , value in dict_ids.items()}\n",
    "        events_=events_check.loc[events_check.series_id==swaped_dict[id_]]\n",
    "        events_[\"timestamp\"] =pd.to_datetime(events_[\"timestamp\"].str[:19] )\n",
    "        prev_lenght=len(df_)\n",
    "        df_=df_.loc[df_.timestamp.dt.date<= events_.timestamp.dt.date.max()]\n",
    "        return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a245af0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.250925Z",
     "iopub.status.busy": "2023-12-05T00:21:10.250670Z",
     "iopub.status.idle": "2023-12-05T00:21:10.258284Z",
     "shell.execute_reply": "2023-12-05T00:21:10.257393Z"
    },
    "id": "bt0G7IBq2Fkz",
    "papermill": {
     "duration": 0.0263,
     "end_time": "2023-12-05T00:21:10.260324",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.234024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def drop_initial_date(df__,model):\n",
    "\n",
    "            if VALIDATE:\n",
    "                df__=df__.loc[~(df__.timestamp.diff()==timedelta(seconds=0))]\n",
    "            inital_time=df__.iloc[0].timestamp\n",
    "            \n",
    "            if model.padding==REPLACE:\n",
    "                intial_padding = (inital_time.hour*60+inital_time.minute - 60*model.initial_hour)*12\n",
    "            elif model.padding==EXTEND:\n",
    "                intial_padding = (inital_time.hour*60+inital_time.minute)*model.initial_hour +12*60*12\n",
    "            if intial_padding >0:\n",
    "                df_ini=pd.DataFrame(np.zeros((intial_padding,len(df__.columns))),columns=df__.columns)\n",
    "                df_ini[\"sleep\"]=np.nan\n",
    "                return pd.concat([df_ini,df__])\n",
    "            else:\n",
    "\n",
    "\n",
    "                return df__.iloc[-intial_padding:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5b342b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.291982Z",
     "iopub.status.busy": "2023-12-05T00:21:10.291725Z",
     "iopub.status.idle": "2023-12-05T00:21:10.324404Z",
     "shell.execute_reply": "2023-12-05T00:21:10.323526Z"
    },
    "id": "UjsdNTdcAogW",
    "papermill": {
     "duration": 0.050666,
     "end_time": "2023-12-05T00:21:10.326276",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.275610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.distribute.distribute_lib import def_function\n",
    "\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "def process_df(df_):\n",
    "            df_[\"timestamp\"]=pd.to_datetime(df_[\"timestamp\"].str[:19])    \n",
    "            df_[\"minute\"]=   df_[\"timestamp\"].dt.hour*60+ df_[\"timestamp\"].dt.minute\n",
    "            df_[\"sine\"]=np.sin(df_[\"minute\"]*np.pi*2/ 1440)\n",
    "            df_[\"cosine\"]=np.cos(df_[\"minute\"]*np.pi*2/ 1440)\n",
    "            return df_\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "def read_data(id_, model ):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        features={}\n",
    "        targets={}\n",
    "        descrp={}\n",
    "        steps_={}\n",
    "        preds_dic_len={}\n",
    "        \n",
    "        features[id_]=[]\n",
    "        targets[id_]=[]\n",
    "        steps_[id_]=[]\n",
    "        df_=pd.read_parquet(f\"/kaggle/working/series/series_{id_}.parquet\")\n",
    "        #df_[\"timestamp\"] = pd.to_datetime(df_[\"timestamp\"] )\n",
    "        df_=process_df(df_)\n",
    "      \n",
    "        \n",
    "        if len(df_)>0:\n",
    "            if model. drop_initial_date:\n",
    "              df_=drop_initial_date(df_,model)\n",
    "            df_=df_.reset_index(drop=True)\n",
    "            preds_dic_len[id_]=len(df_)\n",
    "            steps = range(0,len(df_),model.CFG[\"stride\"])\n",
    "            steps= [step for step in steps if step<len(df_)]\n",
    "            descrp[id_]={\"steps\":len(steps),\"length_df\":len(df_)}\n",
    "            \n",
    "\n",
    "            for step in steps:\n",
    "                sample_=df_.loc[step:step+model.CFG[\"block_size\"]-1,:]\n",
    "                feats=sample_.loc[:,numeric_features].values\n",
    "                if model.sample_normalize:\n",
    "                    feats=sample_normalize(feats)\n",
    "                sine_=sample_[\"sine\"].values.reshape(-1,1)\n",
    "                cosine_=sample_[\"cosine\"].values.reshape(-1,1)\n",
    "             \n",
    "\n",
    "                if len(feats)<model.CFG[\"block_size\"]:\n",
    "                      padding = model.CFG[\"block_size\"] - len(feats)\n",
    "                      padding_values = np.zeros((padding, feats.shape[1]))\n",
    "                      padding_sine = np.zeros((padding, sine_.shape[1]))\n",
    "                      padding_cosine = np.zeros((padding, cosine_.shape[1]))\n",
    "                      \n",
    "                        \n",
    "                      feats = np.vstack([feats, padding_values])\n",
    "                      sine_ = np.vstack([sine_, padding_sine])\n",
    "                      cosine_ = np.vstack([cosine_, padding_cosine])\n",
    "                      \n",
    "\n",
    "                feats=feats.reshape(-1,model.CFG[\"patch_size\"]*2).astype(np.float32)\n",
    "                sine_=sine_.reshape(-1,model.CFG[\"patch_size\"],1).mean(axis=1).reshape(-1,1)\n",
    "                cosine_=cosine_.reshape(-1,model.CFG[\"patch_size\"],1).mean(axis=1).reshape(-1,1)\n",
    "  \n",
    "                \n",
    "                if model.use_temp:\n",
    "                    features[id_].append(np.concatenate((feats,sine_,cosine_),axis=1))\n",
    "\n",
    "                else:\n",
    "                    features[id_].append(feats)\n",
    "\n",
    "\n",
    "\n",
    "                steps_[id_].append(step)\n",
    "\n",
    "        \n",
    "                    \n",
    "                del sample_\n",
    "                    \n",
    "            gc.collect()\n",
    "            \n",
    "\n",
    "    return    features,   descrp,  steps_, df_\n",
    "\n",
    "\n",
    "def read_data_validate(id_, model ):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        features={}\n",
    "        targets={}\n",
    "        descrp={}\n",
    "        steps_={}\n",
    "        preds_dic_len={}\n",
    "        lenghts={}\n",
    "        steps_save={} \n",
    "        features[id_]=[]\n",
    "        targets[id_]=[]\n",
    "        steps_[id_]=[]\n",
    "        df_=pd.read_parquet(f\"/kaggle/input/zzz-series/series/series_{id_}.parquet\")\n",
    "        df_[\"timestamp\"] = pd.to_datetime(df_[\"timestamp\"] )\n",
    "        #df_=process_df(df_)\n",
    "        df_= truncate_days(df_,id_)\n",
    "        #print(len(df_))\n",
    "        events_=events.loc[events.series_id==swapped_dict[id_]].dropna(subset=\"timestamp\")\n",
    "        if len(df_)>0 and len(events_)>0:\n",
    "            if model. drop_initial_date:\n",
    "              df_=drop_initial_date(df_,model)\n",
    "            df_=df_.reset_index(drop=True)\n",
    "            preds_dic_len[id_]=len(df_)\n",
    "            steps = range(0,len(df_),model.CFG[\"stride\"])\n",
    "            steps= [step for step in steps if step<len(df_)]\n",
    "            descrp[id_]={\"steps\":len(steps),\"length_df\":len(df_)}\n",
    "            \n",
    "\n",
    "            for step in steps:\n",
    "                sample_=df_.loc[step:step+model.CFG[\"block_size\"]-1,:]\n",
    "                feats=sample_.loc[:,numeric_features].values\n",
    "                if model.sample_normalize:\n",
    "                    feats=sample_normalize(feats)\n",
    "                sine_=sample_[\"sine\"].values.reshape(-1,1)\n",
    "                cosine_=sample_[\"cosine\"].values.reshape(-1,1)\n",
    "                target_=sample_.loc[:,TARGET].values.reshape(-1,1)\n",
    "\n",
    "                if len(feats)<model.CFG[\"block_size\"]:\n",
    "                      padding = model.CFG[\"block_size\"] - len(feats)\n",
    "                      padding_values = np.zeros((padding, feats.shape[1]))\n",
    "                      padding_sine = np.zeros((padding, sine_.shape[1]))\n",
    "                      padding_cosine = np.zeros((padding, cosine_.shape[1]))\n",
    "                      padding_target = np.empty((padding, cosine_.shape[1])) *np.nan\n",
    "                        \n",
    "                      feats = np.vstack([feats, padding_values])\n",
    "                      sine_ = np.vstack([sine_, padding_sine])\n",
    "                      cosine_ = np.vstack([cosine_, padding_cosine])\n",
    "                      target_ = np.vstack([target_, padding_target])\n",
    "\n",
    "                feats=feats.reshape(-1,model.CFG[\"patch_size\"]*2).astype(np.float32)\n",
    "                sine_=sine_.reshape(-1,model.CFG[\"patch_size\"],1).mean(axis=1).reshape(-1,1)\n",
    "                cosine_=cosine_.reshape(-1,model.CFG[\"patch_size\"],1).mean(axis=1).reshape(-1,1)\n",
    "                targets_=np.nanmean(target_.reshape(-1,model.CFG[\"patch_size\"],1),axis=1).round().astype(np.float16)\n",
    "                #if np.isnan(targets_).sum()!=len(targets_):\n",
    "                if True:\n",
    "                    if model.use_temp:\n",
    "                        features[id_].append(np.concatenate((feats,sine_,cosine_),axis=1))\n",
    "\n",
    "                    else:\n",
    "                        features[id_].append(feats)\n",
    "                    \n",
    "\n",
    "\n",
    "                    steps_[id_].append(step)\n",
    "\n",
    "               \n",
    "                else:\n",
    "                    df_=df_.loc[(df_.index<step)|(df_.index>=step+model.CFG[\"block_size\"])]\n",
    "                    \n",
    "                del sample_\n",
    "                    \n",
    "            gc.collect()\n",
    "            \n",
    "\n",
    "    return    features,   descrp,  steps_, df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eaba78f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.357817Z",
     "iopub.status.busy": "2023-12-05T00:21:10.357553Z",
     "iopub.status.idle": "2023-12-05T00:21:10.366131Z",
     "shell.execute_reply": "2023-12-05T00:21:10.365389Z"
    },
    "id": "C2cqOpl3AogX",
    "papermill": {
     "duration": 0.026387,
     "end_time": "2023-12-05T00:21:10.368078",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.341691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ce = tf.keras.losses.BinaryCrossentropy(reduction='none')\n",
    "\n",
    "def loss_function(real, output, name='loss_function'):\n",
    "\n",
    "    # a mask is applied to not compute nan target\n",
    "    mask = tf.math.logical_not(tf.math.is_nan(real))\n",
    "\n",
    "\n",
    "\n",
    "    y_true = tf.boolean_mask(real, mask)\n",
    "    y_pred = tf.boolean_mask(output, mask)\n",
    "    tf.debugging.check_numerics(y_true, message=\"NaNs in 'real'\")\n",
    "    tf.debugging.check_numerics(y_pred, message=\"NaNs in 'output'\")\n",
    "    loss = ce(tf.expand_dims(y_true,axis=-1),tf.expand_dims(y_pred,axis=-1))\n",
    "    tf.debugging.check_numerics(loss, message=\"NaNs in 'loss'\")\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_lr, warmup_steps=1):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.initial_lr = tf.cast(initial_lr, tf.float32)\n",
    "        self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        return tf.math.minimum(self.initial_lr, self.initial_lr * (step/self.warmup_steps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d280da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.399363Z",
     "iopub.status.busy": "2023-12-05T00:21:10.399109Z",
     "iopub.status.idle": "2023-12-05T00:21:10.500884Z",
     "shell.execute_reply": "2023-12-05T00:21:10.500216Z"
    },
    "id": "9PldskBGAoga",
    "papermill": {
     "duration": 0.119998,
     "end_time": "2023-12-05T00:21:10.502868",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.382870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from scipy.signal import find_peaks\n",
    "def get_event(df,col=\"pred\"):\n",
    "        lstCV = zip(df.series_id, df[col])\n",
    "        lstPOI = []\n",
    "        for (c, v), g in groupby(lstCV, lambda cv:\n",
    "                                (cv[0], cv[1]!=0 and not pd.isnull(cv[1]))):\n",
    "            llg = sum(1 for item in g)\n",
    "            if v is False:\n",
    "                lstPOI.extend([0]*llg)\n",
    "            else:\n",
    "                lstPOI.extend(['onset']+(llg-2)*[0]+['wakeup'] if llg > 1 else [0])\n",
    "        return lstPOI\n",
    "    \n",
    "            \n",
    "def get_events(pred,data_,idx,min_interval=30,patch_size= 12,h=1.3429635e-07,d=30,TAM_CONSIDER=None) :\n",
    "   \n",
    "\n",
    "       \n",
    "        \n",
    "    test_ds=data_\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    days = len(pred)/(17280/100)\n",
    "\n",
    "    submission=pd.DataFrame(columns=[\"step\",\t\"event\",\t\"series_id\",\t\"score\"])\n",
    "    #candidates_onset = np.argsort(-pred[:,0])\n",
    "    #candidates_wakeup =  np.argsort(-pred[:,1])\n",
    "    #n_add=max(1,round(days))\n",
    "\n",
    "    #added_onset=[]\n",
    "    #added_wakeup=[]\n",
    "    #disponibles=list(candidates_onset.copy())\n",
    "    #while len(added_onset)<n_add and len(disponibles)>0:\n",
    "    #    actual = disponibles.pop(0)\n",
    "    #    added_onset.append(actual)\n",
    "    #    disponibles = [x for x in disponibles if abs(x - actual) >= min_interval]\n",
    "\n",
    "    #disponibles=list(candidates_wakeup.copy())\n",
    "    #while len( added_wakeup)<n_add and len(disponibles)>0:\n",
    "    #    actual = disponibles.pop(0)\n",
    "    #    added_wakeup.append(actual)\n",
    "    #    disponibles = [x for x in disponibles if abs(x - actual) >= min_interval]\n",
    "    #added_onset=np.array(  added_onset)\n",
    "    #added_wakeup=np.array(    added_wakeup)\n",
    "    added_onset= np.array(find_peaks( pred[:,0],height=h,distance=d)[0])\n",
    "    added_wakeup= np.array(find_peaks( pred[:,1],height=h,distance=d)[0])\n",
    "    onset = test_ds[['step']].iloc[np.clip(added_onset* TAM_CONSIDER,0,len( test_ds)-1)].astype(np.int32)\n",
    "    onset['event'] = 'onset'\n",
    "    onset['series_id'] =  idx\n",
    "    onset['score']= pred[added_onset,0]\n",
    "    wakeup = test_ds[['step']].iloc[np.clip(added_wakeup* TAM_CONSIDER,0,len( test_ds)-1)].astype(np.int32)\n",
    "    wakeup['event'] = 'wakeup'\n",
    "    wakeup['series_id'] = idx\n",
    "    wakeup['score']= pred[added_wakeup,1]\n",
    "    submission = pd.concat([submission,onset,wakeup],axis=0)\n",
    "\n",
    "    return submission\n",
    "def get_preds_df( val_ids,preds_dict,data,smoothing_length=480,TAM_CONSIDER=None ):\n",
    "    submision=[]\n",
    "    for id_ in tqdm(val_ids):\n",
    "                if len(preds_dict[id_])>0:\n",
    "\n",
    "                    preds=preds_dict[id_]\n",
    "\n",
    "                    df_=data.loc[data.series_id==id_]\n",
    "                    df_=truncate_days(df_,id_)\n",
    "                    data_=df_\n",
    "                    if DROP_INITIAL_DATE  and not  len(data)==450:\n",
    "                      data_=drop_initial_date(data_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    submision.append(get_events(data_,id_,preds,TAM_CONSIDER=TAM_CONSIDER))\n",
    "    submision= pd.concat(submision)\n",
    "    submision[\"step\"]=submision[\"step\"].astype(np.float32)\n",
    "    return submision\n",
    "def get_df(final_preds,df_,model,TAM_CONSIDER):\n",
    "    \n",
    "    #final_preds=np.tile(final_preds.reshape(-1,1),model.CFG[\"patch_size\"]).reshape(-1,1)\n",
    "    if model.STRIDE!=0:\n",
    "        offset= model.CFG[\"block_size\"]- model.STRIDE\n",
    "        #print(f\"Using STRIDE = {model.STRIDE}, offset = {   offset}\")\n",
    "        final_preds_stride= []\n",
    "       \n",
    "        for preds__ in final_preds:\n",
    "        \n",
    "            if len(final_preds_stride)==0:\n",
    "                final_preds_stride.append(preds__ )\n",
    "            elif len(final_preds_stride)==1:\n",
    "                arr= np.concatenate( [ final_preds_stride[len( final_preds_stride)-1][model.STRIDE:,0].reshape(-1,1), preds__ [:len(preds__ )-model.STRIDE,0].reshape(-1,1)  ],axis=1)\n",
    "                final_preds_stride[len( final_preds_stride)-1][model.STRIDE:,0] = np.nanmean(arr,axis=1)\n",
    "                arr=np.concatenate ([final_preds_stride[len(final_preds_stride)-1][model.STRIDE:,1].reshape(-1,1), preds__ [:len(preds__ )-model.STRIDE,1].reshape(-1,1)  ],axis=1)\n",
    "                final_preds_stride[len( final_preds_stride)-1][model.STRIDE:,1] = np.nanmean( arr,axis=1)\n",
    "                final_preds_stride.append(preds__[len(preds__)-model.STRIDE:])\n",
    "                del arr\n",
    "            else:\n",
    "                \n",
    "                arr= np.concatenate( [ final_preds_stride[len( final_preds_stride)-1][model.STRIDE- offset:,0].reshape(-1,1), preds__ [:len(preds__ )-model.STRIDE,0].reshape(-1,1)  ],axis=1)\n",
    "                final_preds_stride[len( final_preds_stride)-1][model.STRIDE- offset:,0] = np.nanmean(arr,axis=1)\n",
    "                arr=np.concatenate ([final_preds_stride[len(final_preds_stride)-1][model.STRIDE- offset:,1].reshape(-1,1), preds__ [:len(preds__ )-model.STRIDE,1].reshape(-1,1)  ],axis=1)\n",
    "                final_preds_stride[len( final_preds_stride)-1][model.STRIDE- offset:,1] = np.nanmean( arr,axis=1)\n",
    "                final_preds_stride.append(preds__[len(preds__)-model.STRIDE:])\n",
    "                del arr\n",
    "            del preds__\n",
    "            \n",
    "          \n",
    "\n",
    "      \n",
    "        final_preds = final_preds_stride   \n",
    "        del final_preds_stride\n",
    "        gc.collect()  \n",
    "    final_preds=np.concatenate(final_preds,axis=0)\n",
    "    final_preds=final_preds[:TAM_CONSIDER * len(final_preds)//TAM_CONSIDER]\n",
    "\n",
    "    if model.use_tam_consider:\n",
    "        \n",
    "        final_preds_r=np.mean(  final_preds.reshape(-1,TAM_CONSIDER,2),axis=1)\n",
    "        del final_preds\n",
    "        gc.collect()\n",
    "        return  final_preds_r*model.weight\n",
    "    else:\n",
    "        return  final_preds*model.weight\n",
    "      \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e3a4155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.533696Z",
     "iopub.status.busy": "2023-12-05T00:21:10.533415Z",
     "iopub.status.idle": "2023-12-05T00:21:10.537136Z",
     "shell.execute_reply": "2023-12-05T00:21:10.536464Z"
    },
    "papermill": {
     "duration": 0.021427,
     "end_time": "2023-12-05T00:21:10.539119",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.517692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1b3fa52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.570032Z",
     "iopub.status.busy": "2023-12-05T00:21:10.569786Z",
     "iopub.status.idle": "2023-12-05T00:21:10.596738Z",
     "shell.execute_reply": "2023-12-05T00:21:10.596069Z"
    },
    "papermill": {
     "duration": 0.044741,
     "end_time": "2023-12-05T00:21:10.598598",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.553857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict_model(models,TAM_CONSIDER=5):\n",
    "    name_save=\"submision.csv\"\n",
    "    for model_ in models:\n",
    "        if model_.model_type==LINEAR:\n",
    "            model=Model(model_.CFG)\n",
    "\n",
    "        elif model_.model_type==ATT:\n",
    "            model=ModelATT(model_.CFG)\n",
    "        elif model_.model_type==CNN:\n",
    "            model=ModelCNN(model_.CFG)\n",
    "        elif model_.model_type==CONV1:\n",
    "            model=ModelConv1()\n",
    "        elif  model_.model_type==LINEAR_lstm_dropout:\n",
    "            model=Model_lstm_dropout()\n",
    "        elif model_.model_type==CONV1_LSTMDROPOUT:\n",
    "            model=ModelConv1_LSTMDROPOUT()\n",
    "        elif model_.model_type==CONV_6:\n",
    "            model=ModelConv6()\n",
    "        elif model_.model_type==CONV_5:\n",
    "            model=ModelConv5()\n",
    "        elif model_.model_type== GRU:\n",
    "            model=ModelGRU(model_.CFG)\n",
    "       \n",
    "        model.load_weights(model_.model_name)\n",
    "        model_.model=model\n",
    "        \n",
    "    submisions=[]\n",
    "    submision=None\n",
    "    df_total=None\n",
    "    dfs_save=[]\n",
    "    #print(ids_test)\n",
    "    for id_ in tqdm(ids_test):\n",
    " \n",
    "        model_= models[0]\n",
    "        if VALIDATE:\n",
    "            features_test,   descrp_test,  steps_test, df_ = read_data_validate(id_,model= model_)\n",
    "        else:\n",
    "            features_test,   descrp_test,  steps_test, df_ = read_data(id_,model=  model_)\n",
    "        features_use={}\n",
    "        features_use[( model_.initial_hour, model_.patch_size)] = [features_test,   descrp_test,  steps_test, df_]\n",
    "        if len(df_)>0:\n",
    "            \n",
    "            \n",
    "            matrix=np.stack(features_test[id_]).reshape((-1, model_. CFG['block_size'] //  model_.CFG['patch_size'],  model_. dim))\n",
    "        \n",
    "            preds_total =  model_.model.predict(matrix,verbose=0)\n",
    "           \n",
    "            if model_.TAM_RESHAPE!=1:\n",
    "                        preds_total =np.tile(   preds_total ,model_.TAM_RESHAPE).reshape(    preds_total .shape[0],    preds_total .shape[1]*model_.TAM_RESHAPE,2)\n",
    "                 \n",
    "     \n",
    "            df_total=  get_df(preds_total,df_,model_,TAM_CONSIDER=TAM_CONSIDER)\n",
    "       \n",
    "            if False:\n",
    "                fig=plt.figure()\n",
    "                plt.plot(np.arange(len(df_total.reshape(-1,2))),df_total.reshape(-1,2)[:,0])\n",
    "                plt.title(f\"ID: {id_}, {model_.model_name}\")\n",
    "                plt.show()\n",
    "\n",
    "            for model_ in models[1:]:\n",
    "                    if (model_.initial_hour, model_.patch_size) in features_use.keys():\n",
    "                        features_test,   descrp_test,  steps_test, df_ =  features_use[(model_.initial_hour, model_.patch_size)] \n",
    "                    else:\n",
    "                        \n",
    "                        if VALIDATE:\n",
    "                            features_test,   descrp_test,  steps_test, df_ = read_data_validate(id_,model=model_)\n",
    "                        else:\n",
    "                            \n",
    "                            features_test,   descrp_test,  steps_test, df_ = read_data(id_,model=model_)\n",
    "                        features_use[(model_.initial_hour, model_.patch_size)] = [features_test,   descrp_test,  steps_test, df_]\n",
    "                    \n",
    "                    matrix=np.stack(features_test[id_]).reshape((-1, model_. CFG['block_size'] //  model_.CFG['patch_size'],  model_. dim))\n",
    "                    \n",
    "                    preds =  model_.model.predict(matrix,verbose=0)\n",
    "                    \n",
    "                    if model_.TAM_RESHAPE!=1:\n",
    "                        preds=np.tile(   preds,model_.TAM_RESHAPE).reshape(preds.shape[0],preds.shape[1]*model_.TAM_RESHAPE,2)\n",
    "               \n",
    "\n",
    "                    df__=  get_df(preds,df_,model_,TAM_CONSIDER=TAM_CONSIDER)\n",
    "                    if False:\n",
    "                        fig=plt.figure()\n",
    "                        plt.plot(np.arange(len(df__.reshape(-1,2))),df__.reshape(-1,2)[:,0])\n",
    "                        plt.title(f\"ID: {id_}, {model_.model_name}\")\n",
    "                        plt.show()\n",
    "                    if len(df__)<len(df_total):\n",
    "                        df_total=df_total[:len(df__)]\n",
    "                    elif len(df__)>len(df_total):\n",
    "                         df__=df__[:len(df_total)]\n",
    "                    df_total+=df__\n",
    "                    \n",
    "            if VALIDATE:\n",
    "                dfs_save.append( (df_total.copy(),df_,id_))\n",
    "\n",
    " \n",
    "            submision = get_events( df_total,df_,id_,patch_size= model_.patch_size,d=19,h=5e-6,TAM_CONSIDER=TAM_CONSIDER)\n",
    "            submisions.append( submision )\n",
    "            \n",
    "            \n",
    "    import pickle as pkl\n",
    "    df_save=dfs_save\n",
    "    file_save =\"preds_save.pkl\"\n",
    "    pkl.dump(df_save,open(    file_save ,\"wb\"))\n",
    "    del df_save\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "\n",
    "    submision=pd.concat(  submisions ) \n",
    "    submision[\"step\"]=submision[\"step\"].astype(np.float32)\n",
    "    \n",
    "\n",
    "    submision=submision.reset_index(drop=True).reset_index(names='row_id')\n",
    "    solution=[]\n",
    "    if VALIDATE:\n",
    "                events=pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\")\n",
    "                for id_ in ids_test:\n",
    "                        events_=events.loc[events.series_id==swapped_dict[id_]].dropna(subset=\"timestamp\")\n",
    "                        events_[\"series_id\"]=  events_[\"series_id\"].transform(lambda x: dict_ids[x])\n",
    "                        solution.append(events_)\n",
    "\n",
    "                solution=pd.concat(solution) .reset_index(drop=True)\n",
    "                solution.to_csv(\"solution.csv\")\n",
    "                tolerances= {\"onset\":[12, 36, 60, 90, 120, 150, 180, 240, 300, 360],\"wakeup\":[12, 36, 60, 90, 120, 150, 180, 240, 300, 360]}\n",
    "                print( score(solution.reset_index(drop=True)[[\"step\",\"series_id\",\"event\"]],submision.reset_index(drop=True)[[\"series_id\",\"event\",\"score\",\"step\"]],tolerances,    series_id_column_name=\"series_id\",time_column_name=\"step\",event_column_name=\"event\", score_column_name=\"score\" ))\n",
    "    return submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c89bbd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.629576Z",
     "iopub.status.busy": "2023-12-05T00:21:10.629288Z",
     "iopub.status.idle": "2023-12-05T00:21:10.633530Z",
     "shell.execute_reply": "2023-12-05T00:21:10.632667Z"
    },
    "papermill": {
     "duration": 0.021997,
     "end_time": "2023-12-05T00:21:10.635498",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.613501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_BASE=0.03\n",
    "W_BASE_5=0.03\n",
    "W_BASE_8=0.005\n",
    "W_CONV=0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9db5c8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.665885Z",
     "iopub.status.busy": "2023-12-05T00:21:10.665630Z",
     "iopub.status.idle": "2023-12-05T00:21:10.674008Z",
     "shell.execute_reply": "2023-12-05T00:21:10.673149Z"
    },
    "papermill": {
     "duration": 0.025665,
     "end_time": "2023-12-05T00:21:10.675828",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.650163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model0=ModelSpec(model_name= f\"/kaggle/input/modelos-critic/models_5LSTM_lognormal/model_weights_8_fold0_all_/model_weights_8_fold0_all\",padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=10 ,patch_size=10,model_dim=160,weight=W_BASE)\n",
    "model1=ModelSpec(model_name= f\"/kaggle/input/modelos-critic/models_5LSTM_lognormal/model_weights_4_fold1_all_/model_weights_4_fold1_all\",padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=10 ,patch_size=10,model_dim=160,weight=W_BASE)\n",
    "model2=ModelSpec(model_name= f\"/kaggle/input/modelos-critic/models_5LSTM_lognormal/model_weights_6_fold2_all_/model_weights_6_fold2_all\",padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=10 ,patch_size=10,model_dim=160,weight=W_BASE)\n",
    "model3=ModelSpec(model_name= f\"/kaggle/input/modelos-critic/models_5LSTM_lognormal/model_weights_6_fold3_all_/model_weights_6_fold3_all\",padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=10 ,patch_size=10,model_dim=160,weight=W_BASE)\n",
    "model4=ModelSpec(model_name= f\"/kaggle/input/modelos-critic/models_5LSTM_lognormal/model_weights_5_fold4_all_/model_weights_5_fold4_all\",padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=10 ,patch_size=10,model_dim=160,weight=W_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f80831bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.707682Z",
     "iopub.status.busy": "2023-12-05T00:21:10.707431Z",
     "iopub.status.idle": "2023-12-05T00:21:10.715974Z",
     "shell.execute_reply": "2023-12-05T00:21:10.715318Z"
    },
    "papermill": {
     "duration": 0.027366,
     "end_time": "2023-12-05T00:21:10.717919",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.690553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model0_test=ModelSpec(model_name= f\"/kaggle/input/modelos-critic/models_5LSTM_lognormal/model_weights_7_fold0_test_/model_weights_7_fold0_test\",padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=10  ,patch_size=10,model_dim=160,weight=W_BASE)\n",
    "model1_test=ModelSpec(model_name= f\"/kaggle/input/modelos-critic/models_5LSTM_lognormal/model_weights_4_fold1_test_/model_weights_4_fold1_test\",padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=10  ,patch_size=10,model_dim=160,weight=W_BASE)\n",
    "model2_test=ModelSpec(model_name= f\"/kaggle/input/modelos-critic/models_5LSTM_lognormal/model_weights_9_fold2_test_/model_weights_9_fold2_test\",padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=10  ,patch_size=10,model_dim=160,weight=W_BASE)\n",
    "model3_test=ModelSpec(model_name= f\"/kaggle/input/modelos-critic/models_5LSTM_lognormal/model_weights_5_fold3_test_/model_weights_5_fold3_test\",padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=10  ,patch_size=10,model_dim=160,weight=W_BASE)\n",
    "model4_test=ModelSpec(model_name= f\"/kaggle/input/modelos-critic/models_5LSTM_lognormal/model_weights_3_fold4_test_/model_weights_3_fold4_test\",padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=10  ,patch_size=10,model_dim=160,weight=W_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbf7ea5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.750306Z",
     "iopub.status.busy": "2023-12-05T00:21:10.750038Z",
     "iopub.status.idle": "2023-12-05T00:21:10.762853Z",
     "shell.execute_reply": "2023-12-05T00:21:10.761998Z"
    },
    "papermill": {
     "duration": 0.030796,
     "end_time": "2023-12-05T00:21:10.764755",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.733959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model0_conv1=ModelSpec(model_name= f\"/kaggle/input/models-conv/models_conv6/model_weights_6_fold0_all/model_weights_6_fold0_all\",padding = REPLACE, use_temp = True,  model_type=CONV1,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=8,weight=W_CONV)\n",
    "model1_conv1=ModelSpec(model_name= f\"/kaggle/input/models-conv/models_conv6/model_weights_9_fold1_all/model_weights_9_fold1_all\",padding = REPLACE, use_temp = True,  model_type=CONV1,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=8,weight=W_CONV)\n",
    "model2_conv1=ModelSpec(model_name= f\"/kaggle/input/models-conv/models_conv6/model_weights_9_fold2_all/model_weights_9_fold2_all\",padding = REPLACE, use_temp = True,  model_type=CONV1,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=8,weight=W_CONV)\n",
    "model3_conv1=ModelSpec(model_name= f\"/kaggle/input/models-conv/models_conv6/model_weights_7_fold3_all/model_weights_7_fold3_all\",padding = REPLACE, use_temp = True,  model_type=CONV1,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=8,weight=W_CONV)\n",
    "model4_conv1=ModelSpec(model_name= f\"/kaggle/input/models-conv/models_conv6/model_weights_6_fold4_all/model_weights_6_fold4_all\",padding = REPLACE, use_temp = True,  model_type=CONV1,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=8,weight=W_CONV)\n",
    "model0_test_conv1=ModelSpec(model_name= f\"/kaggle/input/models-conv/models_conv6/model_weights_5_fold0_test/model_weights_5_fold0_test\",padding = REPLACE, use_temp = True,  model_type=CONV1,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=8,weight=W_CONV)\n",
    "model1_test_conv1=ModelSpec(model_name= f\"/kaggle/input/models-conv/models_conv6/model_weights_8_fold1_test/model_weights_8_fold1_test\",padding = REPLACE, use_temp = True,  model_type=CONV1,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=8,weight=W_CONV)\n",
    "model2_test_conv1=ModelSpec(model_name= f\"/kaggle/input/models-conv/models_conv6/model_weights_7_fold2_test/model_weights_7_fold2_test\",padding = REPLACE, use_temp = True,  model_type=CONV1,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=8,weight=W_CONV)\n",
    "model3_test_conv1=ModelSpec(model_name= f\"/kaggle/input/models-conv/models_conv6/model_weights_5_fold3_test/model_weights_5_fold3_test\",padding = REPLACE, use_temp = True,  model_type=CONV1,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=8,weight=W_CONV)\n",
    "model4_test_conv1=ModelSpec(model_name= f\"/kaggle/input/models-conv/models_conv6/model_weights_4_fold4_test/model_weights_4_fold4_test\",padding = REPLACE, use_temp = True,  model_type=CONV1,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=8,weight=W_CONV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d70f9353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.795558Z",
     "iopub.status.busy": "2023-12-05T00:21:10.795120Z",
     "iopub.status.idle": "2023-12-05T00:21:10.798866Z",
     "shell.execute_reply": "2023-12-05T00:21:10.798083Z"
    },
    "papermill": {
     "duration": 0.020963,
     "end_time": "2023-12-05T00:21:10.800730",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.779767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "199dbe8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.831787Z",
     "iopub.status.busy": "2023-12-05T00:21:10.831082Z",
     "iopub.status.idle": "2023-12-05T00:21:10.896686Z",
     "shell.execute_reply": "2023-12-05T00:21:10.895995Z"
    },
    "papermill": {
     "duration": 0.083162,
     "end_time": "2023-12-05T00:21:10.898659",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.815497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "models_conv_lstmdropout= [e.replace('.data-00000-of-00001','') for e in glob.glob(\"/kaggle/input/models-conv/models_conv6_dropout0_lstmdropout/*/*data*\")]\n",
    "models_conv_lstmdropout=[ModelSpec(model_name= e,padding = REPLACE, use_temp = True,  model_type=CONV1_LSTMDROPOUT,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=8,weight=W_CONV) for e in models_conv_lstmdropout]\n",
    "models_conv_lstmdropout=list(models_conv_lstmdropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b08ae00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:10.930037Z",
     "iopub.status.busy": "2023-12-05T00:21:10.929766Z",
     "iopub.status.idle": "2023-12-05T00:21:10.993129Z",
     "shell.execute_reply": "2023-12-05T00:21:10.992258Z"
    },
    "papermill": {
     "duration": 0.081225,
     "end_time": "2023-12-05T00:21:10.995154",
     "exception": false,
     "start_time": "2023-12-05T00:21:10.913929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "models_lstm_dropout= [e.replace('.data-00000-of-00001','') for e in glob.glob(\"/kaggle/input/modelos-critic/models_5lstm_lognormal_lstmDropout/*/*data*\")]\n",
    "models_lstm_dropout=[ModelSpec(model_name= e,padding = REPLACE, use_temp = True,  model_type=LINEAR_lstm_dropout,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=10 ,patch_size=10,model_dim=160,weight=W_BASE) for e in models_lstm_dropout]\n",
    "models_lstm_dropout=list(models_lstm_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43fb72fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:11.026946Z",
     "iopub.status.busy": "2023-12-05T00:21:11.026694Z",
     "iopub.status.idle": "2023-12-05T00:21:52.327439Z",
     "shell.execute_reply": "2023-12-05T00:21:52.326327Z"
    },
    "papermill": {
     "duration": 41.3191,
     "end_time": "2023-12-05T00:21:52.329467",
     "exception": false,
     "start_time": "2023-12-05T00:21:11.010367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:39<00:00, 13.12s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if VALIDATE:\n",
    "    ids_test= [109,144,106,217,234]\n",
    "    \n",
    "models_stride_5= [e.replace('.data-00000-of-00001','') for e in glob.glob(\"/kaggle/input/d/mpp1998/models-critic2/models_5lstm_lognormal_patzh5/*/*data*\") ]\n",
    "models_stride_5=[ModelSpec(model_name= e,padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=5 ,patch_size=5,model_dim=160,weight=W_BASE, STRIDE=15120) for e in models_stride_5]\n",
    "models_stride_5=list(models_stride_5)\n",
    "\n",
    "models_stride_5_gru= [e.replace('.data-00000-of-00001','') for e in glob.glob(\"/kaggle/input/d/mpp1998/models-critic2/models_5gru_lognormal/*/*data*\") ]\n",
    "models_stride_5_gru=[ModelSpec(model_name= e,padding = REPLACE, use_temp = True,  model_type=GRU,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=5 ,patch_size=5,model_dim=160,weight=W_BASE, STRIDE=15120) for e in models_stride_5_gru]\n",
    "models_stride_5_gru=list(models_stride_5_gru)\n",
    "\n",
    "models_stride= [e.replace('.data-00000-of-00001','') for e in glob.glob(\"/kaggle/input/modelos-critic/models_5lstm_lognormal_stride/*/*data*\") ]\n",
    "models_stride=[ModelSpec(model_name= e,padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=10 ,patch_size=10,model_dim=160,weight=W_BASE, STRIDE=15120) for e in models_stride]\n",
    "models_stride=list(models_stride)\n",
    "\n",
    "models_conv= [e.replace('.data-00000-of-00001','') for e in glob.glob(\"/kaggle/input/models-conv/models_conv6_dropout0/*/*data*\") if \"fold0\" in e or \"fold1\" in e ]\n",
    "models_conv=[ModelSpec(model_name= e,padding = REPLACE, use_temp = True,  model_type=CONV1,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=8,weight=W_CONV) for e in models_conv]\n",
    "models_conv=list(models_conv)\n",
    "\n",
    "\n",
    "models_stride_3= [e.replace('.data-00000-of-00001','') for e in glob.glob(\"/kaggle/input/d/mpp1998/models-critic2/models-5_lstm_lognormlal_path3/*/*data*\") ]\n",
    "models_stride_3=[ModelSpec(model_name= e,padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=3 ,patch_size=3,model_dim=160,weight=W_BASE, STRIDE=15120) for e in models_stride_3]\n",
    "models_stride_3=list(models_stride_3)\n",
    "\n",
    "\n",
    "models_stride_4= [e.replace('.data-00000-of-00001','') for e in glob.glob(\"/kaggle/input/d/mpp1998/models-critic2/models_5lstm_lognroaml_path4/*/*data*\") ]\n",
    "models_stride_4=[ModelSpec(model_name= e,padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=4 ,patch_size=4,model_dim=160,weight=W_BASE, STRIDE=15120) for e in models_stride_4]\n",
    "models_stride_4=list(models_stride_4)\n",
    "\n",
    "models_stride_6= [e.replace('.data-00000-of-00001','') for e in glob.glob(\"/kaggle/input/d/mpp1998/models-critic2/models_5lstm_lognromal_path6/*/*data*\") ]\n",
    "models_stride_6=[ModelSpec(model_name= e,padding = REPLACE, use_temp = True,  model_type=LINEAR,drop_initial_date=True ,sample_normalize=True,use_tam_consider=True, initial_hour=12,TAM_RESHAPE=6 ,patch_size=6,model_dim=160,weight=W_BASE, STRIDE=15120) for e in models_stride_6]\n",
    "models_stride_6=list(models_stride_6)\n",
    "\n",
    "\n",
    "models_6= [e.replace('.data-00000-of-00001','') for e in glob.glob(\"/kaggle/input/models-conv/models_conv_droput0_path6/*/*data*\")  if \"fold0\" in e or \"fold1\" in e]\n",
    "models_6=[ModelSpec(model_name= e,padding = REPLACE, use_temp = True,  model_type=CONV_6,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=6,weight=W_CONV) for e in models_6]\n",
    "models_6=list( models_6)\n",
    "\n",
    "\n",
    "models_4= [e.replace('.data-00000-of-00001','') for e in glob.glob(\"/kaggle/input/models-conv2/models_conv_dropout0_patxh5/*/*data*\") if \"fold0\" in e or \"fold1\" in e]\n",
    "models_4=[ModelSpec(model_name= e,padding = REPLACE, use_temp = True,  model_type=CONV_5,drop_initial_date=True ,sample_normalize=True ,initial_hour=12 ,patch_size=1,model_dim=None,use_tam_consider=True,TAM_RESHAPE=4,weight=W_CONV) for e in models_4]\n",
    "models_4=list(models_4)\n",
    "\n",
    "\n",
    "\n",
    "if len(ids_test)!=3:\n",
    "        \n",
    "    for model in [ models_stride_5+models_stride + models_4+ models_6+ models_conv ]:\n",
    "        submision=predict_model(model,TAM_CONSIDER=5)\n",
    "else:\n",
    "    for model in [models_conv]:\n",
    "\n",
    "            submision=predict_model(model,TAM_CONSIDER=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ac47101",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:52.362050Z",
     "iopub.status.busy": "2023-12-05T00:21:52.361735Z",
     "iopub.status.idle": "2023-12-05T00:21:52.366422Z",
     "shell.execute_reply": "2023-12-05T00:21:52.365535Z"
    },
    "papermill": {
     "duration": 0.023068,
     "end_time": "2023-12-05T00:21:52.368361",
     "exception": false,
     "start_time": "2023-12-05T00:21:52.345293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs_save=pkl.load(open(\"/kaggle/working/preds_save.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b198c57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:52.399908Z",
     "iopub.status.busy": "2023-12-05T00:21:52.399634Z",
     "iopub.status.idle": "2023-12-05T00:21:52.406329Z",
     "shell.execute_reply": "2023-12-05T00:21:52.405488Z"
    },
    "papermill": {
     "duration": 0.024672,
     "end_time": "2023-12-05T00:21:52.408203",
     "exception": false,
     "start_time": "2023-12-05T00:21:52.383531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if VALIDATE:\n",
    "                solution=[] \n",
    "                events=pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\")\n",
    "                for id_ in ids_test:\n",
    "                        events_=events.loc[events.series_id==swapped_dict[id_]].dropna(subset=\"timestamp\")\n",
    "                        events_[\"series_id\"]=  events_[\"series_id\"].transform(lambda x: dict_ids[x])\n",
    "                        solution.append(events_)\n",
    "\n",
    "                solution=pd.concat(solution) .reset_index(drop=True)\n",
    "                solution.to_csv(\"solution.csv\")\n",
    "                tolerances= {\"onset\":[12, 36, 60, 90, 120, 150, 180, 240, 300, 360],\"wakeup\":[12, 36, 60, 90, 120, 150, 180, 240, 300, 360]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcb08172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:52.440220Z",
     "iopub.status.busy": "2023-12-05T00:21:52.439942Z",
     "iopub.status.idle": "2023-12-05T00:21:52.454029Z",
     "shell.execute_reply": "2023-12-05T00:21:52.453116Z"
    },
    "papermill": {
     "duration": 0.032545,
     "end_time": "2023-12-05T00:21:52.455982",
     "exception": false,
     "start_time": "2023-12-05T00:21:52.423437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>series_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>149.0</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id   step   event     series_id     score\n",
       "0       0    5.0  wakeup  0402a003dae9  0.000012\n",
       "1       1  149.0  wakeup  0402a003dae9  0.000009"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41b1ad0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:52.487851Z",
     "iopub.status.busy": "2023-12-05T00:21:52.487582Z",
     "iopub.status.idle": "2023-12-05T00:21:52.494665Z",
     "shell.execute_reply": "2023-12-05T00:21:52.493816Z"
    },
    "papermill": {
     "duration": 0.025124,
     "end_time": "2023-12-05T00:21:52.496499",
     "exception": false,
     "start_time": "2023-12-05T00:21:52.471375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False and VALIDATE:\n",
    "    #for h in np.arange(5e-7,5e-5,5e-7):\n",
    "    for d  in [28,32,40]:\n",
    "        submisions=[]\n",
    "        h=5e-7\n",
    "        #d=8\n",
    "        for (df_total,df_,id_) in dfs_save:\n",
    "            submision = get_events( df_total,df_,id_,patch_size= 10,h=h,d=d)\n",
    "            submisions.append( submision )\n",
    "\n",
    "        submision=pd.concat(  submisions ) \n",
    "        submision[\"step\"]=submision[\"step\"].astype(np.float32)\n",
    "        print(h,d, score(solution.reset_index(drop=True)[[\"step\",\"series_id\",\"event\"]],submision.reset_index(drop=True)[[\"series_id\",\"event\",\"score\",\"step\"]],tolerances,    series_id_column_name=\"series_id\",time_column_name=\"step\",event_column_name=\"event\", score_column_name=\"score\" ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aba2cdad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T00:21:52.528187Z",
     "iopub.status.busy": "2023-12-05T00:21:52.527885Z",
     "iopub.status.idle": "2023-12-05T00:21:52.540784Z",
     "shell.execute_reply": "2023-12-05T00:21:52.539919Z"
    },
    "papermill": {
     "duration": 0.030915,
     "end_time": "2023-12-05T00:21:52.542783",
     "exception": false,
     "start_time": "2023-12-05T00:21:52.511868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>series_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>149.0</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id   step   event     series_id     score\n",
       "0       0    5.0  wakeup  0402a003dae9  0.000012\n",
       "1       1  149.0  wakeup  0402a003dae9  0.000009"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submision.to_csv('submission.csv', index=False)\n",
    "submision"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 6589269,
     "sourceId": 53666,
     "sourceType": "competition"
    },
    {
     "datasetId": 3706667,
     "sourceId": 6507308,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3773509,
     "sourceId": 6527143,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3829983,
     "sourceId": 6657065,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3855818,
     "sourceId": 6684515,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3893790,
     "sourceId": 6849299,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3725487,
     "sourceId": 6867904,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3969971,
     "sourceId": 6994678,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4029767,
     "sourceId": 7009302,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3945605,
     "sourceId": 7064550,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4005753,
     "sourceId": 7115671,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4074964,
     "sourceId": 7120614,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4107176,
     "sourceId": 7122009,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 69.744198,
   "end_time": "2023-12-05T00:21:56.088165",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-05T00:20:46.343967",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
