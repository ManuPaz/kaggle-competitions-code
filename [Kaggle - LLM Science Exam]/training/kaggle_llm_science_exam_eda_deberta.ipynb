{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mktSbsheNLSh","executionInfo":{"status":"ok","timestamp":1694906237334,"user_tz":-120,"elapsed":2,"user":{"displayName":"Manuel Paz Pintor","userId":"06418643142802499585"}}},"outputs":[],"source":[],"id":"mktSbsheNLSh"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4DUhu06Wmgnx","outputId":"95506fb2-13e4-4982-f86f-08129a49bdd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 2.0.1+cu118\n","Uninstalling torch-2.0.1+cu118:\n"]}],"source":["INIT=True\n","if INIT:\n","  !pip uninstall torch -y\n","  !pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cuXXX/torch_stable.html\n","  !pip install einops\n","  !pip install bitsandbytes\n","  !pip install sentencepiece\n","  !pip install accelerate\n","  !pip install transformers\n","  !pip install datasets\n","  !pip install optuna\n","import os\n","\n","from google.colab import drive"],"id":"4DUhu06Wmgnx"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9z7baRfumjlw"},"outputs":[],"source":["if INIT:\n","  drive.mount('/content/drive')\n","  ! pip install kaggle\n","\n","  !mkdir ~/.kaggle\n","\n","\n","  ! cp kaggle.json ~/.kaggle/\n","  ! chmod 600 ~/.kaggle/kaggle.json\n","\n","  ! kaggle competitions download kaggle-llm-science-exam\n","  ! unzip -o kaggle-llm-science-exam.zip -d   kaggle-llm-science-exam\n","\n","  ! kaggle datasets download -d radek1/additional-train-data-for-llm-science-exam\n","  ! unzip -o  additional-train-data-for-llm-science-exam.zip -d    additional-train-data-for-llm-science-exam\n","  ! kaggle datasets download -d mpp1998/data-llm\n","  ! unzip -o  data-llm.zip -d    data-llm\n","  ! kaggle datasets download -d cdeotte/60k-data-with-context-v2\n","  ! unzip -o  60k-data-with-context-v2.zip -d    60k-data-with-context-v2\n","  ! kaggle datasets download -d mpp1998/my-small-dfs\n","  ! unzip -o  my-small-dfs.zip -d    my-small-dfs"],"id":"9z7baRfumjlw"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Hl5w9_95J-A"},"outputs":[],"source":[],"id":"7Hl5w9_95J-A"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9494bfe4"},"outputs":[],"source":["if False:\n","    !pip install datasets\n","    !pip install transformers\n","    !pip install transformers[torch]\n","    !pip install accelerate -U\n"],"id":"9494bfe4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5670c64"},"outputs":[],"source":["import sys\n","sys.version"],"id":"a5670c64"},{"cell_type":"code","execution_count":null,"metadata":{"id":"43f9059a"},"outputs":[],"source":[],"id":"43f9059a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"73fd0777"},"outputs":[],"source":["\n","def map3(predictions, labels):\n","    hits = (-predictions).argsort() == labels.unsqueeze(1)\n","    return (hits[:, 0] * 1 + hits[:, 1] * 1/2 + hits[:, 2] * 1/3).sum().item() / hits.shape[0]"],"id":"73fd0777"},{"cell_type":"code","execution_count":null,"metadata":{"id":"81c47aea"},"outputs":[],"source":["# Importing Libraries\n","\n","# Data Handling\n","import pandas as pd\n","import numpy as np\n","from dataclasses import dataclass\n","from typing import Optional, Union\n","from datasets import Dataset\n","\n","\n","import matplotlib.pyplot as plt\n","\n","\n","# Statistics & Mathematics\n","import scipy.stats as stats\n","from scipy.stats import shapiro, skew\n","import math\n","\n","# RFECV for feature selection\n","from sklearn.feature_selection import RFECV\n","\n","# Machine Learning Pipeline & process\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.base import BaseEstimator, TransformerMixin\n","\n","# Preprocessing data\n","from sklearn.preprocessing import RobustScaler, StandardScaler, QuantileTransformer, FunctionTransformer\n","from sklearn.compose import ColumnTransformer\n","\n","# Model Selection for Cross Validation\n","from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n","\n","# Machine Learning metrics\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, cohen_kappa_score, make_scorer\n","\n","# ML regressors\n","from sklearn.linear_model import HuberRegressor,RANSACRegressor, TheilSenRegressor\n","from sklearn.ensemble import HistGradientBoostingRegressor, StackingRegressor, AdaBoostRegressor, RandomForestRegressor\n","\n","\n","# ML classifiers\n","from sklearn.ensemble import HistGradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n","from sklearn.ensemble import StackingClassifier, VotingClassifier\n","\n","\n","# Clustering model\n","from sklearn.cluster import KMeans\n","\n","\n","\n","# Randomizer\n","import random\n","\n","# Encoder of categorical variables\n","from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n","\n","# Importing HuggingFace's Transformers\n","from transformers import AutoTokenizer, AutoModelForMultipleChoice, Trainer, TrainingArguments, EarlyStoppingCallback\n","from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n","\n","# PyTorch\n","import torch\n","\n","# Hiding warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"id":"81c47aea"},{"cell_type":"markdown","metadata":{"id":"bad4089c"},"source":[],"id":"bad4089c"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4732a029"},"outputs":[],"source":["# Configuring Pandas to exhibit larger columns\n","'''\n","This is going to allow us to read the questions and answers\n","'''\n","pd.set_option('display.max_colwidth', 1000)"],"id":"4732a029"},{"cell_type":"code","execution_count":null,"metadata":{"id":"eaf69dbe"},"outputs":[],"source":["# Checking if GPU is available\n","if torch.cuda.is_available():\n","    print(\"GPU is available\")\n","    device = torch.device('cuda')\n","else:\n","    print(\"GPU is not available\")\n","    device = torch.device('cpu')"],"id":"eaf69dbe"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6a3bacd4"},"outputs":[],"source":["# Defining seed and the template for plots\n","seed = 42\n","plotly_template = 'simple_white'"],"id":"6a3bacd4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4e9392de"},"outputs":[],"source":["df = pd.read_csv('./60k-data-with-context-v2/train_with_context2.csv') # Loading data\n","df.shape\n"],"id":"4e9392de"},{"cell_type":"markdown","metadata":{"id":"f4c9cb57"},"source":["> <p style=\"font-size: 20px\"><b>üìù We have a total of 200 questions. <br><br>\n","    üìù All features, except for <code>id</code>, are categorical features.</b></p>"],"id":"f4c9cb57"},{"cell_type":"code","execution_count":null,"metadata":{"id":"558236ff"},"outputs":[],"source":["if \"id\" in df.columns:\n","  df = df.drop('id', axis = 1)  # Dropping 'Id' columns"],"id":"558236ff"},{"cell_type":"code","execution_count":null,"metadata":{"id":"98fb58c4"},"outputs":[],"source":["# Concatenating original dataframe to extra dataframes\n","augmented_df =  pd.read_csv('/content/my-small-dfs/adjusted_distribution_train_20_000samples.csv')\n","\n","\n","\n","augmented_df=augmented_df.loc[~augmented_df.prompt.isin(df.prompt)].dropna()\n","augmented_df=augmented_df.drop_duplicates(subset=\"prompt\")\n","augmented_df.shape\n"],"id":"98fb58c4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4QVqcfYj_6sh"},"outputs":[],"source":["augmented_df = augmented_df[[ 'prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer',]]\n","augmented_df.head(3)"],"id":"4QVqcfYj_6sh"},{"cell_type":"markdown","metadata":{"id":"bc515fbb"},"source":["> <p style=\"font-size: 20px\"><b>üìù We went from 200 samples to 700 samples.</b></p>"],"id":"bc515fbb"},{"cell_type":"markdown","metadata":{"id":"c1f2a077"},"source":["<p style=\"font-size: 20px\">Now I'm going to split the data, creating a dataframe for training and another for validation. I am going to use 70% of the data for training and 30% for validation.</p>"],"id":"c1f2a077"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5fc2db84"},"outputs":[],"source":["# Creating training and validation sets\n","train_df =augmented_df\n","val_df = df"],"id":"5fc2db84"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ab5ac7c"},"outputs":[],"source":["train_df.shape"],"id":"8ab5ac7c"},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfabfhRKq7in"},"outputs":[],"source":["train_df .isna() .sum(  )"],"id":"IfabfhRKq7in"},{"cell_type":"code","execution_count":null,"metadata":{"id":"02bdcf2e"},"outputs":[],"source":[],"id":"02bdcf2e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"LkwpM1GXrU2t"},"outputs":[],"source":[],"id":"LkwpM1GXrU2t"},{"cell_type":"code","execution_count":null,"metadata":{"id":"502fb813"},"outputs":[],"source":["folding =False\n","\n","from sklearn.model_selection import KFold,StratifiedKFold\n","n_splits = 5\n","if folding:\n","\n","    # Crear una instancia de KFold\n","    kfold = StratifiedKFold(n_splits=n_splits,random_state=21,shuffle=True)\n","\n","    for fold,(train_indice, test_indice) in enumerate(kfold.split(    augmented_df,    augmented_df.answer)):\n","      if fold ==3:\n","        print(fold)\n","\n","        train_df=augmented_df.iloc[train_indice]\n","print(train_df.shape)\n","train_df=train_df.fillna(\"MASK_NAS\")\n","train_df=train_df.loc[~train_df.prompt.isin(df.prompt)]\n","\n","print(train_df.loc[train_df.prompt.isin(df.prompt)].shape)\n","train_df =train_df .drop_duplicates(subset=\"prompt\")\n","print(train_df.shape)"],"id":"502fb813"},{"cell_type":"code","execution_count":null,"metadata":{"id":"98eacdbc"},"outputs":[],"source":["# Converting dataframes into datasets\n","train_ds = Dataset.from_pandas(train_df)\n","val_ds = Dataset.from_pandas(val_df)\n","\n","print('\\nTrain Dataset:\\n')\n","print(train_ds)\n","print('\\nValidation Dataset:\\n')\n","print(val_ds)"],"id":"98eacdbc"},{"cell_type":"markdown","metadata":{"id":"382b61dc"},"source":["<p style=\"font-size: 20px\">Now we convert the dataframes to Datasets.</p>"],"id":"382b61dc"},{"cell_type":"markdown","metadata":{"id":"9d0068b2"},"source":["<p style=\"font-size: 20px\">We are now going to use the <code>AutoTokenizer</code> class from Hugging Face, as well as the <code>from_pretrained()</code> method, to load the token vocabulary pretrained for the de DeBERTa model.</p>"],"id":"9d0068b2"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0a81b471"},"outputs":[],"source":["def competition_score(y_true, y_pred):\n","\n","    \"\"\"\n","    Obtaining score for the model\n","    \"\"\"\n","\n","    ap_at_3 = 0.0\n","    for i in range(len(y_true)):\n","        if y_true[i]==  y_pred[i][0]:\n","            ap_at_3 += 1\n","        elif y_true[i]==  y_pred[i][1]:\n","            ap_at_3 += 1/2\n","        elif y_true[i]==  y_pred[i][2]:\n","            ap_at_3 += 1/3\n","\n","\n","    map3 = ap_at_3 / len(y_true)\n","    return map3\n","\n","def predictions_to_map_output(predictions):\n","    sorted_answer_indices = np.argsort(-predictions) # Sortting indices in descending order\n","    top_answer_indices = sorted_answer_indices[:,:3] # Taking the first three indices for each row\n","    top_answers = np.vectorize(index_to_option.get)(top_answer_indices) # Transforming indices to options - i.e., 0 --> A\n","    return  top_answers\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    y_pred = predictions_to_map_output(logits)\n","    y_true = [index_to_option[label] for label in labels]\n","    print( y_true)\n","    return {'Map@3': np.round(competition_score(y_true, y_pred), 3)}"],"id":"0a81b471"},{"cell_type":"code","execution_count":null,"metadata":{"id":"VAYUm27WvJvS"},"outputs":[],"source":["train_df[\"all\"]=train_df[\"prompt\"]+train_df[\"A\"]+train_df[\"B\"]+train_df[\"C\"]+train_df[\"D\"]+train_df[\"E\"]"],"id":"VAYUm27WvJvS"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ee7d942a"},"outputs":[],"source":["# Setting up answer choices and their respective indices\n","options = 'ABCDE'\n","indices = list(range(5)) # Indexing 0, 1, 2, 3, 4 for each option\n","\n","\n","option_to_index = {option: index for option, index in zip(options, indices)} # Converting options to indices '''A to 0'''\n","index_to_option = {index: option for option, index in zip(options, indices)} # Converting indices to options '''0 to A'''\n","\n","def preprocess_wrapper(tokenizer,MAX_INPUT=350):\n","    def preprocess(example):\n","\n","        first_sentence = [example['prompt']] * 5 # Repeating the same question 5 times\n","        second_sentence = [] # Creating list of possible answers\n","        for option in options:\n","            second_sentence.append(example[option])\n","\n","        # The tokenizer converts the question and answers into 'tokens'.\n","        # 'tokens' are simply a sequence of integers in which each specific integer corresponds to\n","        # a word or subword that BERT is capable of comprehending\n","        tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n","\n","        # Indexing label - A,B,C,D or E - to either 0, 1, 2, 3, 4, or 5\n","        tokenized_example['label'] = option_to_index[example['answer']]\n","\n","        # tokenized_example returns:\n","            # input_ids --> List of lists represents the tokens\n","            # token_type_ids --> A list of lists indicating whether each token belongs to the 1st or 2nd sentence\n","            # attention_mask --> List of list where each inner list is either 1 or 0. 1 are not padding tokens, 0 are padding tokens\n","            # label --> The index for the correct option\n","        return tokenized_example\n","\n","    def preprocess_with_context(example):\n","\n","      first_sentence = [ \"[CLS] \" + example['context'] ] * 5\n","      second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in 'ABCDE']\n","\n","      #tokenized_example = tokenizer(first_sentence, second_sentences, truncation=True)\n","      tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first',\n","                                    max_length=MAX_INPUT, add_special_tokens=False)\n","      tokenized_example['label'] = option_to_index[example['answer']]\n","\n","      return tokenized_example\n","\n","    return preprocess_with_context"],"id":"ee7d942a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"rm-19BaKvw5a"},"outputs":[],"source":[],"id":"rm-19BaKvw5a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e88aa1c3"},"outputs":[],"source":["@dataclass\n","class DataCollatorForMultipleChoice:\n","    '''\n","    This class is designed to handle the formatting and batching the data for mutiple-choice tasks\n","    '''\n","\n","    # The tokenizer to be used for tokenizing the data\n","    tokenizer: PreTrainedTokenizerBase\n","\n","    # The strategy to be used for padding the data\n","    padding: Union[bool, str, PaddingStrategy] = True\n","\n","    # The maximum length for any input sequence\n","    max_length: Optional[int] = None\n","\n","    # If provided, pad the sequences to a multiple of this value\n","    pad_to_multiple_of: Optional[int] = None\n","\n","    def __call__(self, features):\n","        # Finding the correct label key in the features\n","        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n","\n","        # Extracting the labels and removing them from features\n","        labels = [feature.pop(label_name) for feature in features]\n","\n","        # Obtaining batch size\n","        batch_size = len(features)\n","\n","        # Obtaining number of choices\n","        num_choices = len(features[0]['input_ids'])\n","\n","        # Reestructuring features so each question-choice pair becomes a separate example\n","        flattened_features = [\n","            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n","        ]\n","        flattened_features = sum(flattened_features, [])\n","\n","        # Padding all sequences to the same length\n","        batch = self.tokenizer.pad(\n","            flattened_features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors='pt',\n","        )\n","\n","        # Reshaping the batch back into the original format\n","        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n","\n","        # Adding the labels back into the batch as a tensor\n","        batch['labels'] = torch.tensor(labels,\n","                                       dtype=torch.int64)\n","\n","        # Returning the batch\n","        return batch"],"id":"e88aa1c3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"56864a61"},"outputs":[],"source":["model_name=\"/content/drive/MyDrive/checkpoit30456/checkpoints/checkpoint-30456\"\n","\n"],"id":"56864a61"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d26823a4"},"outputs":[],"source":["\n","print(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","# Instantiating model\n","model = AutoModelForMultipleChoice.from_pretrained(model_name)\n","model = model.to(device) # GPU\n","\n","\n","\n"],"id":"d26823a4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"WlEkhN9_0g4v"},"outputs":[],"source":["tokenizer(\"a # b\")"],"id":"WlEkhN9_0g4v"},{"cell_type":"code","execution_count":null,"metadata":{"id":"14FJpD6-O6-z"},"outputs":[],"source":["for param in model.parameters():\n","  if not param.requires_grad:\n","    print(param.requires_grad )\n","  param.requires_grad =True\n"],"id":"14FJpD6-O6-z"},{"cell_type":"code","execution_count":null,"metadata":{"id":"O16ARso4PD69"},"outputs":[],"source":["len([ layer for layer in model.deberta.encoder.layer])"],"id":"O16ARso4PD69"},{"cell_type":"code","execution_count":null,"metadata":{"id":"kkNGKANbp7bV"},"outputs":[],"source":["FREEZE_EMBEDDINGS = True\n","FREEZE_LAYERS=18\n","if FREEZE_EMBEDDINGS:\n","    print('Freezing embeddings.')\n","    for param in model.deberta.embeddings.parameters():\n","        param.requires_grad = False\n","if FREEZE_LAYERS>0:\n","    print(f'Freezing {FREEZE_LAYERS} layers.')\n","    for layer in model.deberta.encoder.layer[:FREEZE_LAYERS]:\n","        for param in layer.parameters():\n","            param.requires_grad = False"],"id":"kkNGKANbp7bV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"TEAonVN8mejn"},"outputs":[],"source":["model_dir = 'finetuned_deberta' # Directory to save model and files\n","output_dir=model_dir\n","checkpoint_dir=\"checkpoints\"\n","# Tokenizing train Dataset\n","r_cols= [e for e in ['prompt', 'A', 'B', 'C', 'D', 'E', 'answer', '__index_level_0__','context','source'] if e in train_ds.features]\n","tokenized_train_ds = train_ds.map(preprocess_wrapper(tokenizer,MAX_INPUT=450), batched=False, remove_columns=r_cols)\n"],"id":"TEAonVN8mejn"},{"cell_type":"code","execution_count":null,"metadata":{"id":"gu5WEnvZrfse"},"outputs":[],"source":["\n","r_cols= [e for e in ['prompt', 'A', 'B', 'C', 'D', 'E', 'answer', '__index_level_0__','context','source']  if e in val_ds.features]\n","tokenized_val_ds = val_ds.map(preprocess_wrapper(tokenizer,MAX_INPUT=650), batched=False,\n","                              remove_columns=r_cols)\n","\n","# Defining parameters\n","training_args = TrainingArguments(\n","    output_dir=checkpoint_dir,\n","    warmup_ratio = .8,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    save_total_limit=5,\n","    learning_rate= 5e-6,\n","    per_device_train_batch_size= 4,\n","    per_device_eval_batch_size= 4,\n","    #gradient_accumulation_steps = 2,\n","    gradient_checkpointing = True,\n","    num_train_epochs=20,\n","    #weight_decay=0.01,\n","    metric_for_best_model = 'eval_loss',\n","    report_to='none',\n",")\n","# Defining Trainer to train the model\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train_ds,\n","    eval_dataset=tokenized_val_ds,\n","\n","    tokenizer=tokenizer,\n","    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n","    compute_metrics = compute_metrics,\n","    callbacks = [EarlyStoppingCallback(early_stopping_patience = 5,\n","                                      early_stopping_threshold = 0.01)]\n",")\n","\n","\n","print(trainer.evaluate())\n","trainer.train()"],"id":"gu5WEnvZrfse"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZxuMYih0N7xW"},"outputs":[],"source":[],"id":"ZxuMYih0N7xW"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wf8AeGNKd6Rb"},"outputs":[],"source":[],"id":"Wf8AeGNKd6Rb"},{"cell_type":"markdown","metadata":{"id":"18rQiHvqkw-J"},"source":[],"id":"18rQiHvqkw-J"},{"cell_type":"markdown","metadata":{"id":"BAlLOjX89Ahn"},"source":[],"id":"BAlLOjX89Ahn"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Sy5f0gEXwal"},"outputs":[],"source":["model.save_pretrained(model_dir)\n","# Save the tokenizer as well\n","tokenizer.save_pretrained(model_dir)\n","print(trainer.evaluate())"],"id":"2Sy5f0gEXwal"},{"cell_type":"code","execution_count":null,"metadata":{"id":"r-3MxItJPtKw"},"outputs":[],"source":["# Source directory to be zipped\n","import shutil\n","source_dir = f\"drive/MyDrive/{output_dir}\"\n","\n","\n","\n","\n","# Create a zip archive of the directory\n","shutil.make_archive(source_dir , 'zip', output_dir)\n","\n","print(f\"Zip archive '{source_dir}' created.\")"],"id":"r-3MxItJPtKw"},{"cell_type":"code","execution_count":null,"metadata":{"id":"QAFYpVJhQHEA"},"outputs":[],"source":["# Source directory to be zipped\n","import shutil\n","\n","for dir in os.listdir(\"checkpoints\"):\n","  try:\n","    print(dir)\n","\n","    source_dir = f\"drive/MyDrive/checkpoints/{dir}\"\n","\n","\n","\n","\n","    # Create a zip archive of the directory\n","    shutil.make_archive(source_dir , 'zip', f\"checkpoints/{dir}\")\n","\n","    print(f\"Checkpoints Zip archive '{source_dir}' created.\")\n","  except Exception as e:\n","    print(e)"],"id":"QAFYpVJhQHEA"}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":19544.443325,"end_time":"2023-08-31T01:49:04.686324","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-08-30T20:23:20.242999","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}